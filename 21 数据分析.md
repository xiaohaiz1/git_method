

plt.figure()---在plt中绘制一张图片

plt.subplot()  ---- 创建单个子图, subplot(nrows,ncols,sharex,sharey,subplot_kw,**fig_kw)

```
import numpy as np
import matplotlib.pyplot as plt
x = np.arange(0, 100)
 
plt.subplot(221)
plt.plot(x, x)
#作图2
plt.subplot(222)
plt.plot(x, -x)
#作图3
plt.subplot(223)
plt.plot(x, x ** 2)
plt.grid(color='r', linestyle='--', linewidth=1,alpha=0.3)
#作图4
plt.subplot(224)
plt.plot(x, np.log(x))
plt.show()
```

plt.subplots()  ---- 创建多个子图

​	

1. fig,axes=plt.subplots(2,2)
2. ax1=axes[0,0]
3. ax2=axes[0,1]
4. *#作图1*
5. ax1.plot(x, x)
6. 
   plt.show()

add_subplots()  ---- 给figure新增子图

```
import numpy as np
import matplotlib.pyplot as plt
x = np.arange(0, 100)
#新建figure对象
fig=plt.figure()
#新建子图1
ax1=fig.add_subplot(2,2,1)
ax1.plot(x, x)
#新建子图2
ax3=fig.add_subplot(2,2,2)
ax3.plot(x, x ** 2)
ax3.grid(color='r', linestyle='--', linewidth=1,alpha=0.3)
#新建子图3
ax4=fig.add_subplot(2,2,3)
ax4.plot(x, np.log(x))
plt.show()
```

add_axes()  ---- 新增子区域, fig.add_axes([left, bottom, width, height]),  该区域可以坐落在figure内任意位置，且该区域可任意设置大小. 如：

left, bottom, width, height = 0.1, 0.1, 0.8, 0.8 表示子区域从figure 10%的位置开始绘制, 宽高是figure的80%

```
 
import matplotlib.pyplot as plt
 
#新建figure
fig = plt.figure()
# 定义数据
x = [1, 2, 3, 4, 5, 6, 7]
y = [1, 3, 4, 2, 5, 8, 6]
#新建区域ax1
#figure的百分比,从figure 10%的位置开始绘制, 宽高是figure的80%
left, bottom, width, height = 0.1, 0.1, 0.8, 0.8
# 获得绘制的句柄
ax1 = fig.add_axes([left, bottom, width, height])
ax1.plot(x, y, 'r')
ax1.set_title('area1')
 
#新增区域ax2,嵌套在ax1内
left, bottom, width, height = 0.2, 0.6, 0.25, 0.25
# 获得绘制的句柄
ax2 = fig.add_axes([left, bottom, width, height])
ax2.plot(x,y, 'b')
ax2.set_title('area2')
plt.show()
```



#### 总结:

1. 字符串方法 补充的

   | 方法                  | 说明                                                         | 示例 |
   | --------------------- | ------------------------------------------------------------ | ---- |
   | concat()              | 实现元素级的字符串连接，可指定分隔符                         |      |
   | contains              | 各字符串是否含有指定模式, 返回布尔型数组                     |      |
   | count                 | 模式的出现次数                                               |      |
   | endswith,  startswith | 相当于对各个元素执行 x.endswith(pattern) 或 x.startswith(pattern) |      |
   | findall               | 计算各字符串的 模式列表                                      |      |
   | get                   | 获取各元素的第 `i`个字符                                     |      |
   | join                  | 指定的 分隔符 将Series中各元素的字符串 连接 起来             |      |
   | len                   | 计算各字符串的长度                                           |      |
   | lower, upper          | 转换大小写。相当于对各个元素执行x.lower() 或x.upper()        |      |
   | match                 | 指定的 正则表达式 对各个 元素 执行 re.match                  |      |
   | pad                   | 字符串的左边，右边或左右两边添加空白符                       |      |
   | center                | 相当于pad(side="both)                                        |      |
   | repeat                | 重复值。例如，st.repeat(3)相当于对各个字符串执行x*3          |      |
   | replace               | 指定字符串替换找到的模式                                     |      |
   | slice                 | 对Series中的各个字符串进行子串截取                           |      |
   | split                 | 分隔符或正则表达式对字符串进行拆分                           |      |
   | strip. rstrip. lstrip | 去除 空白符，包括换行符。相当于对各个元素执行x.strip(), x.rstrip(), x.lstrip() |      |

2. dtype、type()、astype()区别

   1. type() ,  返回数据结构类型（list、dict、numpy.ndarray 等）
   2. dtype() , 返回数据元素的数据类型（int、float等）
   3. astype()函数可用于转化dateframe某一列的数据类型

3. numpy的注意点: =,copy,切片
   1. a=b , 赋值, a,b指向同一个对象, id(a)等于id(b), 完全不复制
   2. a = b[:];   #切片赋值, 会创建新对象a,  id(a) 不等于id(b)
      1. a的数据由b保管, 两个的数据变化是一致的, a与b互相影响
   3. a = b.copy() ,会创建新对象a,  id(a) 不等于id(b),且 a和b互不影响

4. numpy 是包, 有`__init__.py`模块

5. pandas的isna(), isnull 与 numpy的isnan()
   1. numpy里边查找`NaN`值的话，就用 np.isnan()
   2. pandas里边查找`NaN`值的话，要么`.isna()`，要么`.isnull()`。
   3. python里边，pandas是建在[numpy](https://so.csdn.net/so/search?q=numpy)上的（即numpy的定制版），而numpy可是没`na`，也没`null`，只有`np.nan`（是 “Not a Number”的缩写）。因此，pandas用`NaN`
   4. numpy_array[numpy_array.isnan()] = 100;  此方法替换numpy中的np.nan, numpy没有fillna() 方法
   5. df1.fillna(100);   #此方法替换pandas中的NaN

6. DatetimeIndex、PeriodIndex和TimedeltaIndex，它们都可以作为Series和DataFrame的索引

7. numpy.random.choice()  #从a中随机选取指定个数的值

   ```
   numpy.random.choice(a, size=None, replace=True, p=None)
   Generates a random sample from a given 1-D array
   Parameters:	
   a : 1-D array-like or int
   If an ndarray, a random sample is generated from its elements. If an int, the random sample is generated as if a were np.arange(a)
   
   size : int or tuple of ints, optional
   Output shape. If the given shape is, e.g., (m, n, k), then m * n * k samples are drawn. Default is None, in which case a single value is returned.
   
   replace : boolean, optional
   Whether the sample is with or without replacement
   
   p : 1-D array-like, optional
   The probabilities associated with each entry in a. If not given the sample assumes a uniform distribution over all entries in a.
   ```

   

8. numpy.diff(a, n=1,axis=-1)   #沿指定轴计算第N维的离散差值

   a：输入矩阵
   n：可选，代表要执行几次差值
   axis ：默认是最后一个

9. DataFrame.shift(periods=1, freq=None, axis=0)

   periods：类型为int，表示移动的幅度，可以是正数，也可以是负数，默认值是1,移动一次，注意这里移动的都是数据，而索引是不移动的，移动之后没有对应值的，就赋值为NaN。

10. DataFrame数据df1的列 df1['A'];  列名加引号

11. pandas中索引重置set_index和reset_index

    1. DataFrame.set_index(keys, drop=True, append=False, inplace=False, verify_integrity=False)
    2. DataFrame.reset_index(level=None, drop=False, inplace=False, col_level=0, col_fill=”) 
       level  控制了具体要还原的哪个等级的索引 
       drop   为False则索引列会被还原为普通列，True会丢失该列数据，慎重使用。

12. 数据集删除功能： drop 和 del （del慎用）
    插入列： pop() and insert()

    1. drop:(可选择性:原址删除/视图删除）,可多列
        df.drop(self, labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors=’raise’);

      (labels, axis=1 is equivalent to columns=labels)

      说明：drop对多行或多列删除，传入inpalce=True对原数据修改，默认inplace=False

      baby_names.drop([‘Id’,’unname’],axis=1).head()   #不改变baby_names的原址数据

    2. del df[‘…’] 原址数据删除，仅一次删除1列，不可多列

    移动和插入：pop() and insert()
    3. ins = df.pop('class')
    4. df.insert('location', new_name_column, value_inserted_column)
             df.insert(3,'class_insert',ins)

13. [1, 2, 3, 4, 5, 2, 3, 4].count(3)   #统计list格式中3的个数






### 21 数据分析

#### 01-数据分析介绍和环境安装

1. 数据分析: 基础概念和环境
   2. matplotlib
   3. numpy
   4. pandas
2. 数据分析:python数据科学的基础, 机器学习课程的基础
   1. 定义: 用适当的方法对大量数据进行分析,作出判断，采取行动
3. 流程: 提出问题 --> 准备数据 --> 分析数据 --> 获得结论 --> 成果可视化
4. 环境安装
   1. conda  : data science package & environment manager
   2. 创建环境 : conda create --name python_data python=3  #环境名称 python_data
   3. 切换环境:
      1. windows : `activate python_data`
      2. linux/macos :  `source activate python_data`
   4. 官方地址:   `https://www.anaconda.com/download/`
5. jupyter notebook



#### 02 matplotlib折线图

1. matplotlib: Python底层绘图库, 名字取于MATLAB，模仿MATLAB构建

   1. 作用: 可视化图表, 使数据更加客观、更具说服力

2. 代码

   1. ```
      from matplotlib import pyplot as plt #导入pyplot
      x = range(2, 26, 2)  #数据在x轴的位置,是一个可迭代对象
      y = [15,13, 14,5,17,20,25,26, 27, 22, 18, 15] #数据在y轴的位置,是一个可迭代对象
      
      #设置图片
      plt.figure(figsize=(20,8), dpi=80)
      
      #绘图
      #x轴和y轴的数据一起组成了所有要绘制出的坐标
      #分别是(2,15),(4,13),(6,14.5),(8,17....
      #x 轴数据 y 轴数据 是 可迭代对象
      plt.plot(x,y)  #传入x和y , plot绘制出折线图
      
      #设置x轴的 刻度
      _xtick_labels=[i/2 for i in range(4, 49)]
      plt.xticks(range(25, 50))
      plt.yticks(range(min(y), max(y)+1))
      
      #保存
      plt.savefig('./t1.png')
      #展示图形
      plt.show()  #在执行程序的时候展示图形
      ```
      
      

3. 图片大小

   1. ```
      import matplotlib.pyplot as plt
      fig = plt.figure(figsize=(20, 8), dpi=80)
      x = range(2,26, 2)
      y = [15, 13, 14.5, 17, 20, 25, 26, 26, 24, 22, 18, 15]
      plt.plot(x, y)
      plt.savefig('.sig_size.png')
      plt.show()
      ```

   2. figure(), 创建图片对象, 然后在图片对象上绘图

      1. 参数
         1. figsize=(20,8) , 元组, 设定图片大小
         2. dpi参数 , 让图清晰

      2. ```
         figure(num=None, figsize=None, dpi=None, facecolor=None, edgecolor=None, frameon=True)
         参数:
         num : 图像编号或名称，数字为编号，字符串为名称
           figsize : 指定figure的宽和高，单位为英寸
               dpi : 指定绘图对象的分辨率，即每英寸多少个像素，缺省值为80
         facecolor : 背景的颜色
         edgecolor : 边框颜色
           frameon : 是否显示边框
         ```

   3. savefig()  #保存图片, svg矢量图格式, 没有锯齿


   1. 描述信息, 比如x轴和y轴表示什么, 这个图表示什么

4. plt.legend(loc='位置') 函数，给图片加上图例. 

   1. 参数列表： (self,parent, handles, labels, loc=None, numpoints=None, markerscale=None, markerfirst=True, scatterpoints=None, scatteryoffsets=None, prop=None, fontsize=None, borderpad=None, labelspacing=None, handlelength=None, handleheight=None, handletextpad=None, borderaxespad=None, columnspacing=None, ncol=1, mode=None, fancybox=None, shadow=None, title=None, framealpha=None, edgecolor=None, facecolor=None, bbox_to_anchor=None, bbox_transform=None, frameon=None, handler_map=None),  其中:

      edgecolor：图例外框颜色

      facecolor：图例框内填充颜色

      title：图例标题

   2. loc:图例位置, 

      如 plt.legend（loc='upper left'）图例在左上角

      ```
      'best'     : 0
      'upper right'  
      'upper left'  : 2,
      'lower left'  : 3,
      'lower right'  : 4,
      'right'     : 5,
      'center left'  : 6,
      'center right' : 7,
      'lower center' : 8,
      'upper center' : 9,
      'center'    : 10,
      ```
      
      

5. 添加 描述信息表的标题：plt.title(‘内容’);    x轴注释：plt.xlabel(‘内容’):    y轴注释：plt.ylabel(‘内容’)

   

6. x或者y的刻度的间距

   1. ```
      import matplotlib.pyplot as plt
      fig = plt.figure(figsize=(10, 5))
      x = range(2,26, 2)
      y = [15, 13, 14.5, 17, 20, 25, 26, 26, 24, 22, 18, 15]
      plt.plot(x, y)
      
      #设置x刻度
      plt.xticks(x)  
      plt.savefig('.sig_size.png')
      plt.show()
      ```
      
   2. plt.xticks()  #设置x刻度

      1. 刻度太密集时候, 用列表的步长(间隔取值)来解决,matplotib会自动帮我们对应

      2. ```
         #设置x, y刻度
         plt.xticks(range(25,50))
         plt.yticks(range(min(y),max(y)+1))
         ```
         

7. 线条的样式(比如颜色,透明度等)

   1. plt.plot(x,y,ls,lw,c,marker,markersize,markeredgecolor,markerfacecolor,label)
      1. 参数:   x：横坐标；  y：纵坐标；  ls或linestyle：线的形式（‘-’，‘–’，‘：’和‘-.’）；  lw（或linewidth）：线的宽度；   c：线的颜色；   marker：线上点的形状；   markersize或者ms：标记的尺寸，浮点型；   markerfacecolor：点的填充色；   markeredgecolor：标记的边沿颜色;   label：文本标签

8. 特殊的点(比如告诉别人最高点和最低点在哪里)

9. 水印(防伪,防止盗用)

10. 设置字体: 方式1: 函数 `font_manager.FontProperties()`.  方式2: 属性 `fontproperties=my_font`.   方式3:  `matplotlib.rc("font",**font)`

   1. font_manager.FontProperties()

      ```
      from matplotlib import pyplot as plt
      import random
      import matplotlib
      from matplotlib import font_manager
      
      #设置字体
      my_font = font_manager.FontProperties(fname="/System/Library/Fonts/PingFang.ttc")
      
      x = range(0,120)
      y = [random.randint(20,35) for i in range(120)]
      
      plt.figure(figsize=(20,8),dpi=80)
      
      plt.plot(x,y)
      
      #调整x轴的刻度
      _xtick_labels = ["10点{}分".format(i) for i in range(60)]
      _xtick_labels += ["11点{}分".format(i) for i in range(60)]
      #取步长，数字和字符串一一对应，数据的长度一样
      plt.xticks(list(x)[::3], _xtick_labels[::3], rotation=45, fontproperties=my_font)  #rotaion旋转的度数
      
      #添加描述信息
      plt.xlabel("时间",fontproperties=my_font)
      plt.ylabel("温度 单位(℃)",fontproperties=my_font)
      plt.title("10点到12点每分钟的气温变化情况",fontproperties=my_font)

   2. 方式3: `matplotlib.rc("font",**font)`

      ```
      from matplotlib import pyplot as plt
      import random
      import matplotlib
      from matplotlib import font_manager
      
      #windws和linux设置字体的方法
      font = {'family' : 'MicroSoft YaHei',
              'weight': 'bold',
              'size': 15.0
              }
      #matplotlib.rc("font",**font),  kw参数
      matplotlib.rc("font",family='MicroSoft YaHei',weight="bold")
      
      x = range(0,120)
      y = [random.randint(20,35) for i in range(120)]
      
      plt.figure(figsize=(20,8),dpi=80)
      
      plt.plot(x,y)
      
      #调整x轴的刻度
      _xtick_labels = ["10点{}分".format(i) for i in range(60)]
      _xtick_labels += ["11点{}分".format(i) for i in range(60)]
      
      #添加描述信息
      
      #plt.xlabel("时间",fontproperties=my_font)
      
      #plt.ylabel("温度 单位(℃)",fontproperties=my_font)
      
      #plt.title("10点到12点每分钟的气温变化情况",fontproperties=my_font)
      
      plt.xlabel("时间")
      plt.ylabel("温度 单位(℃)")
      plt.title("10点到12点每分钟的气温变化情况")
      plt.show()
      ```

      

      2. linux/mac下面支持的字体:

         1. fc-list  #查看支持的字体
         2. fc-list :lang=zh  #查看支持的中文(冒号前面有空格)
         3. 通过matplotlib 下的font_manager可以解决

11. 设置网格

    1. ```
       from matplotlib import pyplot as plt
       from matplotlib import font_manager
       
       y = [1,0,1,1,2,4,3,2,3,4,4,5,6,5,4,3,3,1,1,1]
       x = range(11,31)
       
       #设置图形大小
       plt.figure(figsize=(20,8),dpi=80)
       
       plt.plot(x,y)
       
       #设置x轴刻度
       _xtick_labels = ["{}岁".format(i) for i in x]  
       plt.xticks(x,_xtick_labels)
       plt.yticks(range(0,9))
       
       #绘制网格, alpha透明度
       plt.grid(alpha=0.1)
       
       #展示
       plt.show()
       ```

       
       

12. 设置图例标签字体,位置

    1. ```
       from matplotlib import pyplot as plt
       from matplotlib import font_manager
       
       y_1 = [1,0,1,1,2,4,3,2,3,4,4,5,6,5,4,3,3,1,1,1]
       y_2 = [1,0,3,1,2,2,3,3,2,1 ,2,1,1,1,1,1,1,1,1,1]
       
       x = range(11,31)
       
       #设置图形大小
       plt.figure(figsize=(20,8),dpi=80)
       
       plt.plot(x,y_1,label="自己",color="#F08080")
       plt.plot(x,y_2,label="同桌",color="#DB7093",linestyle="--")
       
       #设置x轴刻度
       _xtick_labels = ["{}岁".format(i) for i in x]
       plt.xticks(x,_xtick_labels)
       
       # plt.yticks(range(0,9))
       
       #绘制网格
       plt.grid(alpha=0.4,linestyle=':')
       
       #添加图例
       # plt.legend(loc="upper left")
       
       plt.legend()
       #展示
       plt.show()
       ```

    2. 图例标签字体,位置

       1. 方式1: 直接设置

          1. plt.plot(x, y_2, label="同桌", color="#DB7093", linestyle="--")
             1. x,y 坐标点配对数据
             2. color 颜色
             3. label 图例(线条)标签
             4. linestyle 线型

       2. 方式2: legend() 工具

          1. `plt.legend(prop=my_font, loc="upper left")`  #prop 指定图例标签的字体, loc设置图例标签位置, 默认右上角

          2. loc参数的值: 

             1. | Location String | Location Code |
                | --------------- | ------------- |
                | 'best'          | 0             |
                | 'upper right'   | 1             |
                | 'upper left'    | 2             |
                | 'lower left'    | 3             |
                | 'lower right'   | 4             |
                | 'right'         | 5             |
                | 'center left'   | 6             |
                | 'center right'  | 7             |
                | 'lower center'  | 8             |
                | 'upper center'  | 9             |
                | 'center'        | 10            |

13. 图形风格自定义

    1. `plt.plot(x,y,color='r', linestyle='--',  linewidth=5, alpha=0.5)`

    2. <table>
           <tr><td>颜色字符</td><td>风格字符</td></tr>
           <tr><td>r 红色</td><td>-实线</td></tr>
           <tr><td>g 绿色</td><td>--虚线，破折线</td></tr>
           <tr><td>b 蓝色</td><td>-.点划线</td></tr>
           <tr><td>w 白色</td><td>:点虚线, 虚线</td></tr>
           <tr><td></td><td>''留空或空格,无线条</td></tr>
           <tr><td>c 青色</td><td></td></tr>
           <tr><td>m 洋红</td><td></td></tr>
           <tr><td>y 黄色</td><td></td></tr>
           <tr><td>k 黑色</td><td></td></tr>
           <tr><td>0ffe0 16进制</td><td></td></tr>
           <tr><td>0.8灰度值字符串</td><td></td></tr>    
       </table>

14. 总结

    1. 折线图    plt.plot()
    2. 图片的大小和分辨率   plt.figure(figsize=(20,8),dpi=80)
    3. 图片的保存 plt.savefig(目录)
    4. xy轴上的刻度和字符串
       1. xticks()
       2. 刻度稀疏和密集的问题xticks()
    5. 标题,xy轴的lable
       1. plt.title()
       2. plt.xlable()
       3. plt.ylable()
    6. 设置字体方式: `font_manager. fontProperties(fname)` , 或 ` matplotlib.rc(family)`
    7. 图上绘制多个图形(plt多次plot即可)
    8. 添加图例
       1. `plt.plot(x,y_1,label="自己",color="#F08080")`
       2. `plt.legend(loc="upper left")`
    9. 库导入
       1. from matplotlib import pyplot as plt  #绘图模块pyplot.py
       2. from matplotlib import font_manager  #字体关联模块font_manager.py



#### 03 matplotlib常用统计图

1. 概述: 折线图,散点图,柱状图,直方图,箱线图,饼图

   1. 折线图 plot(): 反应数据 变化, 线的上升或下降 表示统计数量的 增减变化
      1. 用途: 数据的变化趋势，反映事物的变化
      2. 场景: 用户点击次数随时间的变化, (不同区域)每天活跃用户数, app每天下载数量, 每天上下班时间
      3. 数量类型: 数据变化
   2. 直方图 hist(): 用于 统计, 连续性的数据, 一组或者多组数据的 `分布统计`, 纵向条纹或线段表示数据分布.  横轴--数据范围，纵轴--分布 
      1. 数量类型: 连续数据
   3. 条形图: 统计.  表的列或行的数据绘制成 `条形图`,   一眼看出大小,比较数据差别
      2. 数据类型: 离散数据
   4. 散点图: 特点: 分布规律(统计)
      1. 两组数据 构成多个 坐标点，考察坐标点的分布. 判断两变量之间是否存在某种 关联
      2. 应用场景: 不同条件(维度)的 关联关系; 数据的 离散聚合
      3. 数据特点:  两个属性的数据,  离群点

2. 散点图 plt.scatter()

   1. ```
      from matplotlib import pyplot as plt
      from matplotlib import font_manager
      
      my_font = font_manager.FontProperties(fname="/System/Library/Fonts/Hiragino Sans GB.ttc")
      y_3 = [11,17,16,11,12,11,12,6,6,7,8,9,12,15,14,17,18,21,16,17,20,14,15,15,15,19,21,22,22,22,23]
      y_10 = [26,26,28,19,21,17,16,19,18,20,20,19,22,23,17,20,21,20,22,15,11,15,5,13,17,10,11,13,12,13,6]
      
      x_3 = range(1,32)
      x_10 = range(51,82)
      
      #设置图形大小
      plt.figure(figsize=(20,8),dpi=80)
      
      #使用scatter方法绘制散点图,和之前绘制折线图的唯一区别
      #x轴 x的元, y轴 y的元
      plt.scatter(x_3,y_3,label="3月份")
      plt.scatter(x_10,y_10,label="10月份")
      
      #调整x轴的刻度
      _x = list(x_3)+list(x_10)
      _xtick_labels = ["3月{}日".format(i) for i in x_3]
      _xtick_labels += ["10月{}日".format(i-50) for i in x_10]
      plt.xticks(_x[::3],_xtick_labels[::3],fontproperties=my_font,rotation=45)
      
      #添加图例
      plt.legend(loc="upper left",prop=my_font)
      
      #添加描述信息
      plt.xlabel("时间",fontproperties=my_font)
      plt.ylabel("温度",fontproperties=my_font)
      plt.title("标题",fontproperties=my_font)
      
      #展示
      plt.show()
      ```
      
      

3. 绘制条形图plt.bar()

   1. 纵向条形图

      ```
      from matplotlib import pyplot as plt
      from matplotlib import font_manager
      my_font = font_manager.FontProperties(fname="/System/Library/Fonts/Hiragino Sans GB.ttc")
      
      #2个list数据
      a = ["战狼2","速度与激情8","功夫瑜伽","西游伏妖篇","变形金刚5：最后的骑士","摔跤吧！爸爸","加勒比海盗5：死无对证","金刚：骷髅岛","极限特工：终极回归","生化危机6：终章","乘风破浪","神偷奶爸3","智取威虎山","大闹天竺","金刚狼3：殊死一战","蜘蛛侠：英雄归来","悟空传","银河护卫队2","情圣","新木乃伊",]
      b=[56.01,26.94,17.53,16.49,15.45,12.96,11.8,11.61,11.28,11.12,10.49,10.3,8.75,7.55,7.32,6.99,6.88,6.86,6.58,6.23]
      
      #设置图形大小
      plt.figure(figsize=(20,15),dpi=80)
      
      #绘制条形图, 只接受数字的可迭代对象; width宽度,默认0.8
      plt.bar(range(len(a)),b,width=0.3)
      
      #设置字符串 代替x轴刻度
      plt.xticks(range(len(a)),a,fontproperties=my_font,rotation=90)
      
      xticks() 实现数字与字符串的对应
      
      plt.savefig("./movie.png")
      plt.show()
      ```

      

   2. 横向条形图

      ```
      #绘制条形图 (横向)
      plt.barh(range(len(a)),b,height=0.3,color="orange")
      
   3. 场景: 数量统计, 频率统计(市场饱和度)
   
4. 绘制直方图plt.hist()

   1. ```
      from matplotlib import pyplot as plt
      from matplotlib import font_manager
      
      a=[131,  98, 125, 131, 124, 139, 131, 117, 128, 108, 135, 138, 131, 102, 107, 114, 119, 128, 121, 142, 127, 130, 124, 101, 110, 116, 117, 110, 128, 128, 115,  99, 136, 126, 134,  95, 138, 117, 111,78, 132, 124, 113, 150, 110, 117,  86,  95, 144, 105, 126, 130,126, 130, 126, 116, 123, 106, 112, 138, 123,  86, 101,  99, 136,123, 117, 119, 105, 137, 123, 128, 125, 104, 109, 134, 125, 127,105, 120, 107, 129, 116, 108, 132, 103, 136, 118, 102, 120, 114,105, 115, 132, 145, 119, 121, 112, 139, 125, 138, 109, 132, 134,156, 106, 117, 127, 144, 139, 139, 119, 140,  83, 110, 102,123,107, 143, 115, 136, 118, 139, 123, 112, 118, 125, 109, 119, 133,112, 114, 122, 109, 106, 123, 116, 131, 127, 115, 118, 112, 135,115, 146, 137, 116, 103, 144,  83, 123, 111, 110, 111, 100, 154,136, 100, 118, 119, 133, 134, 106, 129, 126, 110, 111, 109, 141,120, 117, 106, 149, 122, 122, 110, 118, 127, 121, 114, 125, 126,114, 140, 103, 130, 141, 117, 106, 114, 121, 114, 133, 137,  92,121, 112, 146,  97, 137, 105,  98, 117, 112,  81,  97, 139, 113,134, 106, 144, 110, 137, 137, 111, 104, 117, 100, 111, 101, 110,105, 129, 137, 112, 120, 113, 133, 112,  83,  94, 146, 133, 101,131, 116, 111,  84, 137, 115, 122, 106, 144, 109, 123, 116, 111,111, 133, 150]
      
      #计算组数
      d = 3  #组距,每个小组端点的距离  bin_width
      #组数=（最大值-最小值）/ 组距
      num_bins = (max(a)-min(a))//d
      
      #设置图片的大小
      plt.figure(figsize=(20,8),dpi=80)
      
      #绘直方图, plt.hist([1,2,3],组数)
      plt.hist(a,num_bins,normed=True)  #指定a数据源,可迭代对象. 
      #高度是区间内数据的个数
      
      #设置x轴的刻度
      plt.xticks(range(min(a),max(a)+d,d))
      
      plt.grid()
      plt.show()
      ```
      
   3. 场景: 

      1. 年龄分布
      2. 一段时间内用户点击次数 (次数,时间)
      3. 用户活跃时间的分布, (用户数, 时间)

5. 总结 : 

   1. matplotlib.plot(x,y)  #折线图

   2. matplotlib.bar(x,y)  #条形图
      1. plt.bar(x,y,width=0.3）
      2. plt.barh(x,y,height=0.3）

   3. matplotlib.scatter(x,y)  #散点图

   4. matplotlib.hist(data,bins,normed)  #直方图

   5. xticks, yticks的设置
      1. plt.xticks()
      2. plt.yticks()

   6. label,titile,grid的设置 
      1. plt.xlabel()
      2. plt.ylabel()
      3. plt.title()
      4. plt.grid()

   7. 图片的大小和保存图片
      1. figsize属性
      2. savefig()

   8. 流程总结: 明确问题, 选择图形的呈现方式, 准备数据, 绘图和图形完善

   9. plotly绘图工具

      1. 可视化工具中的github
      2. 比于matplotlib更简单,图形更加漂亮,兼容matplotlib和pandas
      3. 用法:简单,照着文档写即可, https://plotly.com/python/

   10. Matplotlib 的figure基本使用, 总结:

      1. figure, add_subplot(): 图片中添加子图

         ```
         import matplotlib.pyplot as plt
         import numpy as np
         
         # 如果不创建figure对象，matplotlib将自动创建一个figure对象
         
         fig = plt.figure()
         print(type(fig))
         arr = np.random.randn(100)
         
         #通过add_subplot来分隔figure，表示在figure的不同位置上作图
         
         ax1 = fig.add_subplot(2,2,1)
         ax2 = fig.add_subplot(2,2,2)
         ax3 = fig.add_subplot(2,2,3)
         ax4 = fig.add_subplot(2,2,4)
         ```

      2. 折线图 plot

         ```
         ax2.plot(arr)   # 一个数据源
         ax3.plot(arr)
         ax1.plot(arr)
         plt.show()
         
      3. 直方图 hist

         ```
         # 直方图 hist
         
         arr = np.random.randn(100)
         
         # 第一个参数是数据集，bins 参数代表展现数据的直方个数，color 参数可以指定颜色, alpha 参数可以指定透明度(默认是1，表示不透明)
         plt.hist(arr, bins = 20, color = 'c', alpha = 0.5) # 一个数据源
         plt.show()
         ```

         1. bins的边缘紧紧挨着

      4. 散点图 scatter

         1. ```
            # x 表示x轴的标签
            x = [1, 2, 3, 4]
            
            # y 表示y轴的标签
            y = [2, 4, 6, 8]
            
            # 创建散点图
            plt.scatter(x, y)   # x数据源,y数据源
            plt.show()
            ```

      5. 柱状图  bar

         1. ```
            import matplotlib.pyplot as plt
            import numpy as np
            x = np.arange(10)
            y1, y2 = np.random.randint(10, 50, size = (2, 10))
            
            fig = plt.figure(figsize = (8, 5), dpi = 100)
            ax = plt.subplot(1,1,1)
            
            # 宽度偏移量
            width = 0.25
            
            # x 表示柱子所在的横坐标位置， y1 表示纵坐标位置，width表示柱子的宽度(默认是0.8 英寸), color 指定黄色
            ax.bar(x, y1, width, color = 'y', alpha = 0.5)
            
            # x + width 表示基于原先位置增加 width偏移量（刚好是y1柱子的宽度), y2 表示纵坐标位置， color 指定红色
            ax.bar(x + width, y2, width, color='r', alpha = 0.5)
            
            # 指定 x轴标记的位置
            ax.set_xticks(x + width / 2)
            ax.set_xticklabels(['a','b','c','d','e','f','g','h','i','j'])
            plt.savefig("bar.png")   #ax.savefig('bar.png') 报错
            plt.show()
            ```

      6. 混淆矩阵 imshow

         1. ```
            plt.imshow(np.random.rand(8, 6))   #8行6列
            
            # plt.imshow(np.random.rand(8, 6), cmap=plt.cm.ocean)
            
            plt.colorbar()
            plt.show()
            ```

      17. 多个子图 同时绘图, subplots()

          1. ```
             #subplots() 创建 ，fig对象 和 subplot数组
             fig, ax = plt.subplots(2,2)
             #type(fig)  #<class 'matplotlib.figure.Figure'>
             #type(ax)   #<class 'numpy.ndarray'>
             #ax   #array([[<AxesSubplot:>, <AxesSubplot:>],
                    [<AxesSubplot:>, <AxesSubplot:>]], dtype=object)
             
             ax[0,1].hist(np.random.randn(100), bins=20, color= 'g', alpha=0.2)
             ax[1,0].imshow(np.random.rand(5, 5))
             #plt.colorbar(ax = subplot_arr[1,0])
             plt.show()
             ```

      8. 颜色、标记和线形

         1. ```
            # plt.plot(np.random.randint(10, 50, 20), color = "red", marker = "v", linestyle= "dashdot")
            
            plt.plot(np.random.randint(10, 50, 20), "rv-.")
            plt.show()
            ```

      9. 图框, 子图

         1. ```
            # 返回一个fig 和 axes 对象(唯一一个)
            fig, ax = plt.subplots(1)   #plt.subplots(1,1) 等价
            ```

         2. ```
            # 返回一个fig 和 axes 对象(唯一一个)
            fig, ax = plt.subplots(2,2)
            ```

      10. 刻度、标签、标题、图例

          1. plt.xlim、plt.ylim 设置 横纵 坐标 轴范围 
             plt.xlabel、plt.ylabel 设置坐标轴名称 
             plt.xticks、plt.yticks设置坐标轴刻度

          2. ```
             fig, ax = plt.subplots(2,2)
             
             # 设置刻度范围
             ax[1,1].set_ylim([0, 1000])
             
             # 设置x轴显示的刻度值
             ax[0,1].set_yticks(range(0, 1000, 200))
             
             # 设置y轴显示的刻度值，十二个月的英文简写
             ax[1,0].set_xticklabels(['Jan', 'Feb','Mar','Apr','May','Jun','Jul','Aug', 'Sep', 'Oct', 'Nov','Dec'])
             ```

          3. ```
             fig, ax = plt.subplots(1)
             
             # 设置 x轴的标签
             ax.set_ylabel("Money")
             
             # 设置 y轴的标签
             ax.set_xlabel("Month")
             ```

          4. ```
             # 设置整个绘图的title （年度报告）
             plt.title("Annual Statement")
             ```

          5. ```
             fig, ax = plt.subplots(2,2)
             ax[0,1].plot(np.random.randint(300, 880, 12), label = u"huangmenji", color='r')
             ax[1,0].plot(np.random.randint(300, 800, 12), label = u"kaoroubanfan")
             ax[1,1].plot(np.random.randint(300, 800, 12), label = u"huangqiaoshaobing")
             plt.show()
             ```

          6. ```
             fig, ax = plt.subplots(1,1)
             
             # 显示图例
             ax.legend()
             plt.savefig("eat.png")
             
             #显示绘图结果
             plt.show()
             ```

   11. 示例

       1. ```
          #coding: utf-8
          
          import matplotlib.pyplot as plt
          
          # figsize = 11, 9
          # figure, ax = plt.subplots(figsize = figsize)
          
          x1 =[0,5000,10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000, 55000]
          y1=[0, 223, 488, 673, 870, 1027, 1193, 1407, 1609, 1791, 2113, 2388]
          x2 = [0, 5000, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 45000, 50000, 55000]
          y2 = [0, 214, 445, 627, 800, 956, 1090, 1281, 1489, 1625, 1896, 2151]
          
          #设置输出的图片大小
          
          figsize = 11, 9
          figure, ax = plt.subplots(figsize=figsize)
          ```

       2. ```
          #在同一幅图片上画两条折线
          
          A, = plt.plot(x1, y1, '-r', label='A', linewidth=5.0)
          B, = plt.plot(x2, y2, 'b-.', label='B', linewidth=5.0)
          ```

       3. ```
          # 设置图例并且设置图例的字体及大小
          
          font1 = {'family': 'Times New Roman',
                   'weight': 'normal',
                   'size': 23,
                   }
                   
          #handles --- 图例上面画出的各个artist（lines, patches）
          legend = plt.legend(handles=[A, B], prop=font1)
          ```
          
       4. ```
          # 设置坐标刻度值的大小以及刻度值的字体
          
          plt.tick_params(labelsize=23)
          labels = ax.get_xticklabels() + ax.get_yticklabels()
          
          # print labels
          
          [label.set_fontname('Times New Roman') for label in labels]
          
          # 设置横纵坐标的名称以及对应字体格式
          
          font2 = {'family': 'Times New Roman',
                   'weight': 'normal',
                   'size': 30,
                   }
          plt.xlabel('round', font2)   #x轴标签, x轴刻度值
          plt.ylabel('value', font2)   #y轴标签, y轴刻度值
          plt.show()
          ```

6. jupyter notebook 数据处理过程要放到一个cell中,否则图不显示

#### 04 numpy 之 数组

1. numpy.ndarray : 科学计算的基础库

2. 示例 : 数组类型 numpy.ndarray

   1. ```
      import numpy as np
      import random
      
      #使用numpy生成数组,得到ndarray的类型
      t1 = np.array([1,2,3,])
      print(t1)   #[1 2 3], 数组
      print(type(t1))  #<class 'numpy.ndarray'>
      t1  #array([1, 2, 3])
      ```

      1. 小结
         1. list 元素用`,`(逗号) 隔开
         2. 数组(矩阵) 元素 用 `空格` 隔开
         3. np.matrix() 只表示二维数据，而 np.array 表示 N 维数据. 
         4. 不用print()打印时  t1输出 `array([1,2,3])`  数组

   2. ```
      t2 = np.array(range(10))
      print(t2)  #[0 1 2 3 4 5 6 7 8 9]
      print(type(t2))  #<class 'numpy.ndarray'>
      ```

   3. ```
      t3 = np.arange(4,10,2)
      print(t3)   #[4 6 8]
      print(type(t3))  #<class 'numpy.ndarray'>
      print(t3.dtype)  #int32, 元素数据的类型
      ```

   4. ```
      #numpy中的数据类型
      t4 = np.array(range(1,4),dtype="i1")
      print(t4)  #[1 2 3]
      print(t4.dtype)  #int8, 属性dtype 数据的类型
      ```

   5. ```
      #numpy中的bool类型
      t5 = np.array([1,1,0,1,0,0],dtype=bool)
      print(t5)  #[ True  True False  True False False]
      print(t5.dtype)  #bool 元素数据类型
      ```

   6. ```
      #调整数据类型
      t6 = t5.astype("int8")  #元素 修改为指定类型
      print(t6)  #[1 1 0 1 0 0]
      print(t6.dtype)  #int8
      ```

   7. ```
      t7 = np.array([random.random() for i in range(10)])
      print(t7)  #[0.95759728 0.43405071 0.51715277 0.29447557 0.12092037 0.72036654 0.26325976 0.35724902 0.57279337 0.22685677]
      print(t7.dtype)  #float64
      ```

   8. ```
      #小数的处理
      t8 = np.round(t7,2)
      print(t8)  #[0.79 0.52 0.23 0.87 0.2  0.57 0.24 0.27 0.43 0.59]
      ```

3. 元素的数据类型

   1. int,"int32", "int64" ,float, "float32",bool

      1. | 类型                                                     | 类型代码                       | 说明         |
         | -------------------------------------------------------- | ------------------------------ | ------------ |
         | int8, uint8, int16, uint16, int32, uint32, int64, uint64 | i1, u1, i2, u2, i4, u4, i8, u8 |              |
         | float16, float32, float64, float128                      | f2, f4或f, f8或d, f16或g       |              |
         | complex16, complex128, complex256                        | c8, c16, c32                   |              |
         | bool                                                     | ?                              | True,  False |
         |                                                          |                                |              |

         

   2. t1.dtype  #查看元素数据类型

   3. t1.astype()  #修改元素类型

4. 数组的形状

   1. ```
      a = np.array([[3,4,5,6,7,8],[3,4,5,6,7,9]])
      a.shape   #(2, 6)
      a.shape[0]  #2
      a.shape[1]  #6
      ```

   2. ```
      b=a.reshape(3,4)
      
      b #输出
      array([[3, 4, 5, 6],
             [7, 8, 3, 4],
             [5, 6, 7, 9]])
             
      print(b) #输出
      [[3 4 5 6]
       [7 8 3 4]
       [5 6 7 9]]
      ```

   3. b.flatten()  #拍扁, 转为 一维数组

5. 数组运算

   1. 数组和数的计算

      1. `a = np.array([[3,4,5,6,7,8],[3,4,5,6,7,9]])`
      2. a+1
         1. array([[ 4,  5,  6,  7,  8,  9],
                        [ 4,  5,  6,  7,  8, 10]])
      3. a*3
         1. array([[ 9, 12, 15, 18, 21, 24],
                        [ 9, 12, 15, 18, 21, 27]])
      4. numpy的广播机制
         1. 加减乘除的值 被广播到所有的元素上

   2. 数组和数组的计算

      1. 行列数分别相等时, 对应元素 加,乘

         1. ```
            a=np.array([[3, 4, 5, 6, 7, 8], [3, 4, 5, 6, 7, 9]])
            b=np.array([[3, 4, 5, 6, 7, 8], [3, 4, 5, 6, 7, 9]])
            
            a+b  #array([[ 6,  8, 10, 12, 14, 16], [ 6,  8, 10, 12, 14, 18]])
            
            a * b  #array([[ 9, 16, 25, 36, 49, 64],[ 9, 16, 25, 36, 49, 81]])
            ```

      2. 行数不等,列数相等

         1. 原则:增维,低维数组变成高位数组

         2. ```
            d = np.array([3, 4, 5, 6, 7, 8])
            
            a-d  #array([[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1]])
            
            d-a  #array([[ 0,0,0,0,0,0], [ 0,0,0,0,0,-1]])
            
            a+d  #array([[ 6,8,10,12,14,16],[ 6,8,10,12,14,17]])
            
            a*d  #array([[ 9,16,25,36,49,64],[ 9,16,25,36,49,72]])
            ```

      3. 后缘维度: 从 末尾 开始算起的维度, 

         2. 轴长度相等,或其中一方的长度为1, 则广播兼容
   
6. 轴(axis)

7. 小结

   1. print(t1), 没有 , 逗号
   2. t1  #直接打印,有逗号



#### 05 numpy 读取本地数据和索引

1. numpy读取--np.loadtxt(), 数组/矩阵的读取, numpy索引和切片

   1. ```
      import numpy as np
      
      us_file_path = "F:/jupyter_notebook/youtube_video_data/US_video_data_numbers.csv" #绝对路径
      uk_file_path = "F:/jupyter_notebook/youtube_video_data/GB_video_data_numbers.csv"
      
      #unpack=True时,返回的行是csv文件的列,  pack是打包的意思
      t1 = np.loadtxt(us_file_path,delimiter=",",dtype="int",unpack=True)
      print(t1)
      ```
      
      1. 输出
      
         1. ```
            [[4394029 7860119 5845909 ...  142463 2162240  515000]
             [ 320053  185853  576597 ...  4231   41032    34727]
             [   5931   26679   39774 ...  148    1384     195  ]
             [  46245       0  170708 ...  279    4737     4722 ]]
            ```
      
         
      
   2. ```
      #unpack=False,在与原csv文件一样的行列
      t2 = np.loadtxt(us_file_path,delimiter=",",dtype="int",unpack=False)
      
      print(t2)
      ```
      
      1. ```
         [[4394029  320053    5931     46245]
          [7860119  185853   26679     0    ]
          [5845909  576597   39774    170708]
          ...
          [ 142463  4231     148       279  ]
          [2162240  41032    1384      4737 ]
          [515000   34727    195       4722 ]]
         ```
      
         
      
   3. ```
      #取行
      print(t2[2])
      ```

      1. `[5845909  576597   39774  170708]`

   4. ```
      #取连续的多行
      print(t2[2:4])  #切片, 左闭右开
      ```

      1. ```
         [[5845909  576597   39774  170708]
          [2642103  24975    4542   12829 ]]
         ```

   5. ```
      #取不连续的多行
      print(t2[[2,8,10]])
      
      #输出
      [[5845909  576597   39774  170708]
       [1338533  69687    678    5643  ]
       [859289   34485    726    1914  ]]
      ```

      ```
      print(t2[[2,10,3],2:3])  #取行号2,10,3行的列号2的行
      # 输出
      [[39774]
       [  726]
       [ 4542]]
      ```

   6. ```
      #取列
      print(t2[:,0])
      
      #输出
      [4394029 7860119 5845909 ...  142463 2162240  515000]  #一列的输出为一维数组
      ```

   7. ```
      #取连续的多列
      print(t2[:,2:])
      
      #输出
      [[5931   46245 ]
       [26679  0     ]
       [39774  170708]
       ...
       [148    279   ]
       [1384   4737  ]
       [195    4722  ]]
      ```

   8. ```
      #取不连续的多列
      print(t2[:,[0,2]])
      
      #输出
      [[4394029    5931]
       [7860119   26679]
       [5845909   39774]
       ...
       [ 142463   148  ]
       [2162240   1384 ]
       [ 515000   195  ]]
      ```

   9. ```
      #取行和列，取第3行，第4列的值
      a = t2[2,3]
      print(a)  #170708, 行与列的交点
      print(type(a))  #<class 'numpy.int32'>
      ```

   10. ```
       #取多行和多列，取第3行到第五行，第2列到第4列的结果
       
       b = t2[2:5,1:4]
       print(b)  #是行和列交叉点的位置
       
       #输出
       [[576597  39774 170708]
        [ 24975   4542  12829]
        [ 96666    568   6666]]
       ```

   11. ```
       #取多个不相邻的点
       
       c = t2[[0,2,2],[0,1,3]]
       print(c)
       
       #输出
       [4394029  576597  170708]  #选出来的结果是（0，0） （2，1） （2，3）
       
       #输出class 是 numpy.ndarray
       ```

2. 小总结

   1. `np.loadtxt(fname,dtype=np.float,delimiter=None,skiprows=0,usecols=None,unpack=False)`
      1. 参数
         1. dtype  默认情况, 较大的数据会变成科学计数的方式
         2. unpack
            1. False,  默认情况, 原外形输出, 多少条数据,就多少行
            2. True, 列变成行, 相当于转置
         3. frame, 文件、字符串或产生器，可以是.gz或bz2压缩文件
         4. dtype, 数据类型，可选，CSV的字符串以什么数据类型读入数组中，默认np. float
         5. delimiter, 分隔字符串，默认是任何空格，改为逗号
         6. skiprows, 跳过前x行，一般跳过第一行表头
         7. usecols, 读取指定的列，索引，元组类型 
         9. 如果为True，返回的数组将被转置，因此参数可能是用' ' x, y, z = loadtxt(…)' '解压。 当与结构化的为每个字段返回数据类型、数组。 默认是False。

3. numpy加载csv文件方法

   1. np.loadtxt()  方式

      1. ```
         filename = "F:/jupyter_notebook/presidential_polls.csv"
         
         data_arr = np.loadtxt(filename, # 需要打开的csv文件的文件名
                               delimiter = ",", # csv文件的分隔符
                               dtype=str, # 数据元素按编字符串格式存储 , str类型
                               usecols=(3, 17, 18, 19) #要读取的列的索引,dtype时必选
                              )
         print(data_arr)
         #输出
         [['matchup' 'adjpoll_clinton' 'adjpoll_trump' 'adjpoll_johnson']
          ...
          ['"Clinton vs. Trump vs. Johnson"' '31.62721' '44.65947' '']]
         ```

   2. np.genfromtxt()  方式

      1. ```
         filename = "F:/jupyter_notebook/presidential_polls.csv"
         
         data_arr = np.genfromtxt(filename, # 需要打开的csv文件的文件名
                    delimiter = ",", # csv文件的分隔符
                    dtype=str, # 按字符串存储数据，不在转换为字节码
                    usecols=(3, 17, 18, 19) #要读取的列的索引,dtype时必选
                   )
         
         print(data_arr)
         #输出
         [['matchup' 'adjpoll_clinton' 'adjpoll_trump' 'adjpoll_johnson']
          ...
          ['"Clinton vs. Trump vs. Johnson"' '31.62721' '44.65947' '']]
         ```

4. numpy中数值的修改

   1. ```
      a = np.array([[ 5, 6, 7, 8],[5, 6, 7, 8],[5, 6, 7, 9]])
      a[1,[1,3]]=20  #修改行列交点的值
      a  #array([[ 5,  6,  7,  8],
                 [ 5, 20,  7, 20],
                 [ 5,  6,  7,  9]])
      ```

5. numpy数组的布尔索引

   1. `a<7`   #返回布尔索引
      1. array([[ True,  True, False, False],
                     [ True, False, False, False],
                     [ True,  True, False, False]])
   2. `a[a<7]=0`   #布尔索引定位, 赋值, 修改 a
      1. array([[ 0,  0,  7,  8],
                     [ 0, 20,  7, 20],
                     [ 0,  0,  7,  9]])
   3. a[a<7]  #布尔索引定位, 取值
      1. array([5, 6, 5, 5, 6])

6.  `np.where(a<7,3,20)`,  #三元运算符

   1. ```
      np.were(a<7,3,20)  #a中小于7的替换为3, 大于等于7的替换为20. 一次性改变, 一份为二
      
      a #输出
      array([[ 3,  3, 20, 20],
             [ 3, 20, 20, 20],
             [ 3,  3, 20, 20]])
      ```

7. clip(7,10)

   1. ```
      a = np.array([[ 5.,  6.,  7.,  8.], [ 5., 20.,  7., 20.], [ 5.,  6., np.nan,  np.nan]])
      
      a.clip(7,10)  #a中小于7的代替为7, 大于10的代替为10, 其他不变, np.nan不变
      
      a #输出
      array([[ 7.,  7.,  7.,  8.],
             [ 7., 10.,  7., 10.],
             [ 7.,  7., nan, nan]])
      ```

   2. 一份 为三

   2. np.clip(a,min,max,out = None)   #clip（）剪断，限制数组的上下界,   

8. CSV : Comma-Separated Value, 逗号分隔值文件. 显示 为 表格状态

   1. 源文件: 每一行的数据表示一条记录
   
9. 转置/转换 , (实例方法, 类方法)

   1. `a = np.array([[ 5, 6, 7, 8],[5, 6, 7, 8],[5, 6, 7, 9]])`
   2. 实例方法, 3方法, 效果相同
      1. `a.transpose()`   #a不变, 返回值变换
         1. #array([[5, 5, 5],
                          [6, 6, 6],
                          [7, 7, 7],
                          [8, 8, 9]])
      2. `a.swapaxes(1,0)`  #轴交换, 二维时与a.transpose()功能一样
         1. #array([[5, 5, 5],
                          [6, 6, 6],
                          [7, 7, 7],
                          [8, 8, 9]])
      3. `a.T`    #a不变, 返回值变换
         1. array([[5, 5, 5],
                         [6, 6, 6],
                         [7, 7, 7],
                         [8, 8, 9]])
   3. 类方法
      1. np.transpose(arr)  #
      2. np.swapaxis(arr, 1, 0)  #轴1, 轴0 交换

10. 示例

    1. ```
       import numpy as np
       from matplotlib import  pyplot as plt
       
       us_file_path = "F:/jupyter_notebook/youtube_video_data/US_video_data_numbers.csv"
       uk_file_path = "F:/jupyter_notebook/youtube_video_data/GB_video_data_numbers.csv"
       
       # t1 = np.loadtxt(us_file_path,delimiter=",",dtype="int",unpack=True)
       
       t_us = np.loadtxt(us_file_path,delimiter=",",dtype="int")
       
       #取评论的数据
       t_us_comments = t_us[:,-1]
       
       #选择比5000小的数据
       t_us_comments = t_us_comments[t_us_comments<=5000]
       print(t_us_comments.max(),t_us_comments.min())
       
       d = 50
       bin_nums = (t_us_comments.max()-t_us_comments.min())//d
       
       #绘图片
       plt.figure(figsize=(20,8),dpi=80)
       plt.hist(t_us_comments,bin_nums)
       
       
       plt.show()
       ```

11. 数据来源:https://www.kaggle.com/datasnaek/youtube/data

#### 06 numpy中的 `np.nan` 和常用的方法

1. np.inf, np.-inf,   正无穷， 负无穷.  数字除以0  返回 `inf` 或 `-inf`, python报错. 

   1. infinity,  a = np.inf
   
2. np.nan 是,not a number.  

   1. np.NAN,   np.nan 两者等价.	

      1.  a = np.nan,  去掉 `np.` 报错
      2.  np.nan: 缺失出现nan, 不合适的计算,如无穷大(inf)减去无穷大

   2.  注意点: `np.nan != np.nan`

   1. ```
         def fill_ndarray(t1):
          for i in range(t1.shape[1]):  #遍历每一列
                 temp_col = t1[:,i]  #当前的一列
              #统计数组中非零元素的个数
                 nan_num = np.count_nonzero(temp_col!=temp_col)
              if nan_num !=0: #不为0，说明当前这一列中有np.nan
                     temp_not_nan_col = temp_col[temp_col==temp_col] #当前列不为nan的array
         
                     # 选中当前为np.nan的位置，赋值为 不为nan的均值
                     temp_col[np.isnan(temp_col)] = temp_not_nan_col.mean()
             return t1
         
         if __name__ == '__main__':
             t1 = np.arange(24).reshape((4, 6)).astype("float")
             t1[1, 2:] = np.nan
             print(t1)
             t1 = fill_ndarray(t1)
             print(t1)
         ```
         
         1. 根据 `np.nan != np.nan`,  用np.count_nonzero(temp_col != temp_col) 计算 np.nan的个数

   3.  np.isnan(t)  判断元素是否是 np.nan

      1. ```
      t = np.array([[ 5.,  6.,  7.,  8.], [ 5., 20.,  7., 20.], [ 5.,  6., np.nan, np.nan]])
         np.isnan(t)
      
         #输出
      array([[False, False, False, False], [False, False, False, False], [False, False,  True,  True]])
         ```

         1. bool 数组可以作 数组的 bool索引

      2. ```
         t[np.isnan(t)]=0  #np.nan 位置重赋值为0
         ```

   4.  np.nan处理方法: 替换 , 删除

      1. 替换
         1. 0替换: 一组数据,把 `np.nan` 替换为0,  均值变小
         2. 一般替换方式
         1. 均值替换, 中值替换
      2. 删除有缺失值的 1 行

3. 行交换, 列交换

   1. 行交换 `t[[2,5],:]=t[[5, 2], :]`
   2. 列交换 `t[:,[2, 5]] = t[:,[5, 2]]`
   3.  切片  : `[]`

4. np.random.seed(10)  #10种子 

   1. ```
      import numpy as np
      
      np.random.seed(10)
      
      #随机产生一个数组
      t = np.random.randint(0,20,(3,4))
      print(t)
      ```

5. 拼接, hstack() , vstack()

   1. 0轴拼接, 数组添加列, np.hstack(a,b), h: horizontally(水平拼接)

      1. ```
         t = np.array([[ 5.,  6.,  7.,  8.],
                       [ 5., 20.,  7., 20.],
                       [ 5.,  6., np.nan, np.nan]])
                                
         zeros_data = np.zeros((3,1)).astype(int)
         us_data = np.hstack((t,zeros_data))
         ```

      2. 结果

         ```
         array([[ 5.,  6.,  7.,  8.,  0.],
                [ 5., 20.,  7., 20.,  0.],
                [ 5.,  6., nan, nan,  0.]])
         ```

      3. ```
         ones_data = np.ones((3,1)).astype(int)
         uk_data = np.hstack((t,ones_data))
         ```

      4. 结果

         ```
         array([[ 5.,  6.,  7.,  8.,  1.],
                [ 5., 20.,  7., 20.,  1.],
                [ 5.,  6., nan, nan,  1.]])
         ```

   2. 轴1拼接,拼接两组数据, np.vstack(a,b), v: vertically(垂直拼接)

      1. ```
         #拼接两组数据
         
         final_data = np.vstack((us_data,uk_data))
         print(final_data)
         ```

      2. 输出

         ```
         [[ 5.  6.  7.  8.  0.]
          [ 5. 20.  7. 20.  0.]
          [ 5.  6. nan nan  0.]
          [ 5.  6.  7.  8.  1.]
          [ 5. 20.  7. 20.  1.]
          [ 5.  6. nan nan  1.]]
         ```

6. 常用算法1,  (类方法, 实例对象方法)

   1. 数据

      1. ```
         t=np.array([[ 9,  4, 15,  0],
                     [17, 16, 17,  8],
                     [ 9,  0, 10,  8]])
         ```

   2. sum()  求和,  ( 类方法, 实例方法)

      1. t.sum(axis=None)  #113, 类方法
      2. np.sum(t,axis=None)  #113, 对象方法
      3. t.sum(0)  #array([35, 20, 42, 16])
      4. t.sum(1)  #array([28, 58, 27])

   3. mean()  均值,  ( 类方法, 实例方法)

      1. t.mean(axis=None)   #9.416666666666666
      2. t.mean(axis=0)   #array([11.66666667,  6.66666667,  14. ,  5.33333333])
      3. np.mean(t,0)      #array([11.66666667,  6.66666667, 14. ,  5.33333333])
      4. np.mean(t, 1)    #array([ 7.  , 14.5 ,  6.75])

   4. median() 中值, 有类方法, 没有 实例方法

      1. np.median(t, axis=None)
      2. np.median(t, 0)
      3. np.median(t, 1)
      4. 中值 有类方法, 没有实例方法

   5. max() 最大值,  ( 类方法, 实例方法)

      1. t.max(axis=None)  #17,  
      2. t.max(0), t.max(1)
      3. np.max(t,1)  #array([15, 17, 10])
      4. np.max(t, 0),  np.max(t)

   6. min() 最小值, ( 类方法, 实例方法)

      1. t.min() , t.min(0),  t.min(1)  
      2. np.min(t,1),  np.min(t, 1), np.min(t)

   7. ptp() 极值,  ( 类方法, 实例方法)

      1. t.ptp()  #17
      2. t.ptp(0), t.ptp(1)
      3. np.ptp(t,0)   #array([ 8, 16,  7,  8])
      4. np.ptp(t, 1),  np.ptp(t, None)

   8. std()  标准差,  ( 类方法, 实例方法)

      1. np.std(t, axis=0)   #array([3.77123617, 6.79869268, 2.94392029, 3.77123617])
      2. np.std(t)
      3. t.std(axis=0)
      4. t.std(axis=None)  #5.780114377953279

   9. var()  方差,  ( 类方法, 实例方法)

      1. t.var(), t.var(0), t.var(axis=1)
      2. np.var(t), np.var(t, 0), np.var(t, 1)

7. 常用方法2, (只有类方法, 没有实例方法)

   1. 数据:    arr = np.random.randn(3, 4)      #3行4列数组

      
      
   2. np.ceil()  #所有元素变成整数, 最接近的比自己大的整数, (只有类方法)
      1. `print(np.ceil(arr))`  
         1. [[-0.  1. -0. -0.]
             [ 2. -1.  1.  1.]
             [ 2. -1. -0.  1.]]
      
   3. np.floor()    #取最接近的比自己小的整数, (只有类方法)
      1. `print(np.floor(arr))`
         1. [[-1.  0. -1. -1.]
             [ 1. -2.  0.  0.]
             [ 1. -2. -1.  0.]]
      
   4. np.rint()   #四舍五入, (只有类方法, 没有实例方法)
      1. `print(np.rint(arr))`
         1. [[ 1.  1.  1. -2.]
             [ 0. -1. -1. -0.]
             [ 1.  0.  1. -1.]]
      
   5. np.abs()    #绝对值, (只有类方法, 没有实例方法)
      1. `print(np.abs(arr))`
         1. [[0.59698258 1.15311517 0.77129899 1.63859897]
             [0.35108384 1.10395872 1.19938489 0.46898571]
             [1.09880531 0.07241172 0.84493762 1.06208511]]
      
   6. np.isnan()   #判断是否是np.nan (只有类方法, 没有实例方法)
      1. `print(np.isnan(arr))`
         1. [[False False False False]
             [False False False False]
             [False False False False]]
      
   7. np.multiply()    #矩阵乘法, (只有类方法, 没有实例方法)
      
      1. `np.multiply(arr, arr)`
      
   8. np.divide()    #矩阵除法, (只有类方法, 没有实例方法)
      
      1. `np.divide(arr, arr)`
      
   9. np.where()    #三元运算符, (只有类方法, 没有实例方法)
      
      1. `np.where(arr < 0, -1, 0)`

8. 常用方法 之 累加/累乘

   1. 数据
      
      arr=np.array([[3, 1, 0, 1],
          [5, 1, 0 ,5],
          [6, 5, 7, 9]])
      
   2. np.cumsum()    #累加和,  ( 类方法, 实例方法)
      1. `print(np.cumsum(arr))` #[ 3  4  4  5 10 11 11 16 22 27 34 43]
      2. arr.cumsum()  #array([ 3  4  4  5 10 11 11 16 22 27 34 43], dtype=int32)
      
   3. np.cumprod()    #累乘积,  ( 类方法, 实例方法)
      1. np.cumprod(arr)  #array([3 3 0 0 0 0 0 0 0 0 0 0], dtype=int32)
      2. arr.cumprod()  #array([3 3 0 0 0 0 0 0 0 0 0 0], dtype=int32)

9. 常用方法4 之 元素判断/元素索引

   1. 数据:    arr = np.random.rand(3, 4)     # 3行4列
   2. np.any(arr);  np.any(arr, axis=0/1)   #数组里有任一元素满足条件，返回True.( 类方法, 实例方法)
      1. np.any(arr > 0.5)  #类方法
      2. (arr>0.5).any()  #实例方法
   3. np.all();  np.all(arr, axis=0/1)    #所有元素满足条件，返回True. ( 类方法, 实例方法)
      1. np.all(arr > 0.5)  #类方法
      2. (arr>0.5).all()  #实例方法
   4. 最大/最小值 索引(位置), ( 类方法, 实例方法)
      1. np.argmax(arr, axis=0);   arr.argmax(0);   arr.argmax(1);
      2. np.argmin(arr, axis=1);   arr.argmin(0);   arr.argmin(1);

10. numpy 常用方法5 之常用数组

    1. `0` 元素数组

       1. np.zeros((3,4))  #参数是形状元组
       2. np.zeros((3,4), int)  ##参数是形状元组, 元素类型int

    2. `1` 元素数组

       1.  `np.ones((3, 4))`
       2. `np.ones((3, 4), int)`

    3. 对角线 `1` 元素 数组

       1. `np.eye(3)`
       2. `np.eye((3, 4)) 报错`

    4. 空数组

       1. `np.empty((3, 4), int)`  #空数组的元素值是随机的, 不是空的
    
    5. list创建数组
    
       1. ```
          list = range(10)  #python中序列列表
          arr = np.array(list)
          ```
          
       2. np.arange(10)  #numpy中序列数组

    6. reshape()  维度转换, (类方法, 实例方法)
    
       1. `arr.reshape(4, 3)`,  `arr.reshape((4, 3))`  #两种参数都是正确的
       2. `np.reshape(arr, (4, 3))`

    7. arr.astype()   #元素类型转换 ,只有实例方法, 没有类方法

       1. arr.astype(np.int32);  arr.astype('int32');
       2. 报错: arr.astype(int32), arr.astype('np.int32')  没有int32, 'np.int32'类型
    
11. array的 属性

    1. arr.ndim  #返回数组的维度
       1.  np.ndim(arr);   #arr.ndim对应的类方法,  没有实例方法
    2. arr.shape   #数据的形状
       1. np.shape(arr)   #对应的类方法,  没有实例方法
    3. arr.size   # 数组大小
       1. np.size(arr)    #对应的类方法,  没有实例方法
    
12. numpy生成随机数 之 np.random,  有类方法, 没有实例方法

    1. `np.random.rand(d0, d1,...dn)`   #dn维度, 均匀分布, 浮点数, 范围: 0-1
       2.  arr = np.random.rand(3, 4)   #二维数组
    2. `np.random.randn(d0, d1, ...dn)`  #dn维度, 标准正态分布, 浮点数, 平均数 0 , 标准差 1
       2.  arr = np.random.randn(3,4)  #二维数组

    下面的randint, uniform, normal ,自己指定数值范围, 与 rand, randn不一个体系. rand, randn在0-1范围内的.

    1. `np.random.randint(low, high, (size)) `   #范围 low, high,  大小size
       2. arr = np.random.randint(-10, 20, size = (3, 4))
    2. `np.random.uniform(low, high, (size))`  #均匀分布, low起始值,high结束值, size形状
       2. arr = np.random.uniform(-10, 20, (3, 4))
    3. `np.random.normal(loc,  scale, size=(n,m))`  #正态分布中随机抽取样本, loc(均值),  标准差scale, 形状size
       1. np.random.normal(loc=3, scale=4, size=(4,5))

    随机打乱原数组的序列

    1. `np.random.shuffle(arr)`    #

13.  `np.nan`  #缺失值, 填充均值

    1. ```
       import numpy as np
       t = np.array([[0,1,2,3,4,5],[6,7,np.nan,9,10,11],[12,13,14,np.nan,16,17],[18,19,20,21,22,23]], dtype=np.float)
       
       #类型指定没有引号
       
       def fill_nan_by_column_mean(t):
           for  i in range(t.shape[1]):
               nan_num = np.count_nonzero(t[:,i][t[:,i]!=t[:,i]])
               if nan_num > 0:
                   now_col = t[:, i]
                   now_col_not_nan = now_col[np.isnan(now_col) == False].sum()
                   now_col_mean = now_col_not_nan / (t.shape[0] - nan_num)
                   t[:, i] = now_col
       ```

14. 小结

    1. 选择一行或者多行的数据
    2. 行或列赋值
    3. 大于10的值替换为10
    4. np.where
    5. np.clip
    6. 转置（交换轴）
    7. 读取和保存csv
    8. np.nan和np.inf
    9. 统计函数
    10. 标准差, 在相同的大小范围内的出现概率是等可能的
    11. 正太分, 呈钟型，两头低，中间高，左右对称
    12. numpy的注意点: =,copy,切片
        1. a=b , 赋值, a,b指向同一个对象, 完全不复制, id(a)等于id(b)
        2. a = b[:];   #切片赋值, 会创建新对象a,  id(a) 不等于id(b)
           1. a的数据由b保管, 两个的数据变化是一致的, a与b互相影响
        3. a = b.copy() ,会创建新对象a,  id(a) 不等于id(b),且 a和b互不影响

#### 07 pandas 之 Series

1. pandas读取csv中的文件

   1. ```
      import pandas as pd
      
      #pandas读取csv中的文件
      df = pd.read_csv("./dogNames2.csv")
      print(df[(800<df["Count_AnimalName"])|(df["Count_AnimalName"]<1000)])
      ```

2. pandas数据格式: Series 一维, 带标签 数组; DataFrame 二维, 是Series 的容器  

   3. Series 生成示例

      1. ```
         #<module 'string' from 'D:\\Python3.8.3\\lib\\string.py'>
         import string
         import pandas as pd
         import numpy as np
         t = pd.Series(np.arange(4), index=list(string.ascii_uppercase[:4]))
         ```
         
      2. `t`
      
         <table>
             <tr><td>A</td><td>0</td></tr>
             <tr><td>B</td><td>1</td></tr>
             <tr><td>C</td><td>2</td></tr>
             <tr><td>D</td><td>3</td></tr>
             <tr><td colspan=2>dtype:int32</td></tr>
         </table>
      
      3. `type(t)`   #`pandas.core.series.Series`

3. pd.Series()   #生成Series对象

   1. 字典推到式得到 Series

      1. `a={string.ascii_uppercase[i]:i for i in range(10)}`

         1. ```
            {'A': 0,
             'B': 1,
             'C': 2,
             'D': 3,
             'E': 4,
             'F': 5,
             'G': 6,
             'H': 7,
             'I': 8,
             'J': 9}
            ```
            
            
         
      2. `pd.Series(a)`   #生成 Series 实例对象

      3. 常用属性

         1. t.index   # Index(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'], dtype='object')
            1. type(t.index)   #pandas.core.indexes.base.Index
         2. t.values  #array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64)
            1. type(t.values)  #<class 'numpy.ndarray'>, 即 numpy的数组
      
      4. Series复合索引???
      
         1. X.swaplevel()
         2. X.swaplevel()['h']
      
   2. list 得到 Series 实例

      1. `ser = pd.Series(['a','b','c','d','e'],[1,2,3,4,'g'])`
         1. 参数1 是 数据
         2. 参数2 是 索引 index
      2. 索引 获取 元素.  不是下标
         1. `ser['g']`  #`'e'`,    ser[5] 报错
      3. `ser.name='series_name'`  #对ser命名为 series_name
      4. `ser.index.name = 'index_name'`  #对索引 命名

4. 函数应用

   数据:

   1. ```
      lst = range(15, 25)
      ser = pd.Series(lst)
      ```

   2. ```
      df1 = pd.DataFrame(np.random.randn(3,4)-10)
      ```

      1.  ```
         #df1
                    0          1          2          3
         0 -10.477967 -10.487656 -10.376098  -9.430426
         1 -10.392302 -10.151766 -10.292077 -10.131941
         2  -9.135147  -7.937367 -10.266852 -10.864886
         ```


   高阶函数:

   1. ser.apply() 实例方法, (没有类方法), 高阶函数

      1. Series

         1. `ser.apply(lambda x: x+1)`   #实例方法

      2. DataFrame

         1. ```
            func = lambda x: x.max()
            df1.apply(func) #默认axis=0
            df1.apply(func, axis=1)
            ```

   2. applymap(),  实例方法(没有类方法),  高阶函数

      1. 对DataFrame对象的所有 元素 操作

         1. ```
            func2 = lambda x : x + x
            df1.applymap(func2)
            ```

      2. Series 没有 applymap() 方法

   排序: sort_index(), sort_values()

   1. sort_index()  索引排序 , (实例方法, 没有类方法)
      1. Series
         1. `ser.sort_index(ascending=True)`  #默认按升序排序   ascending = True
      2. DataFrame
         1. `df1.sort_index(ascending=True, axis=1)`  #默认升序 ascending = True
         2. 参数 axis 指定轴方向(行索引/列索引)
   2. sort_values()  值排序 , 实例方法  (没有类方法)
      1. Series
         1. `ser.sort_values(ascending=True)`  #默认True,  False
      2. DataFrame
         1. `df1.sort_values(by=0, ascending=True, axis=1)`  #默认True,  False, by的例名称不要 引号
         2. 参数 axis 指定轴方向(行索引/列索引)

    `NaN` , 缺失数据

   1. ```
      df1 = pd.DataFrame([
                        [1, 2., np.nan, np.nan],
                        [np.nan, 3, 4, np.nan],
                        [2,7,4,2]
                        ] )
      ```
      
   2. `isnull()` 判断 `NaN` 值,如果是NaN则为True，否则为False. (实例方法, 没有类方法)

      1. `df1.isnull()`  #判断元素是否为NaN

   3. `dropna()`   去除含NaN的行/列，默认 去除行. (实例方法, 没有类方法)

      1. `df1.dropna()`;  #原df1不变
      2. `df1.dropna(axis=1)`   #axis = 1 时，去除列

   4. `fillna()`  #将NaN值替换为指定的值. (实例方法, 没有类方法)

      1. `df1.fillna(0.))`;   #原df1不变

#### Timestamp、Period、Timedelta时间对象

1. Timestamp: 从Python标准库的 datetime 类继承过来的，表示时间轴上的一个时刻。它提供了 时区转换功能

   1. **Timestamp()**  创建任意时间点(时间戳)

      ```
      pd.Timestamp('2018-03-16 21:01:34')  #<class 'pandas._libs.tslibs.timestamps.Timestamp'>
      
   1. **Timestamp.now()**  获取当前时间， 是**不包含时区信息**的本地时间

      ```
      now=pd.Timestamp.now()
      now
      ```

   3. **.tz_localize()**  为当前时间**指定时区**

      ```
      now_shanghai=now.tz_localize("Asia/Shanghai")
      now_shanghai
      ```

      ```
      import pytz #导入时区, 包名, 有__init__.py模块
      pytz.common_timezones  #时区列表
      ```

      

2. Period 时间段 :  某年、某月、某日、某小时等。freq : 决定时间的长短

   1. 调用 **pd.Period.now()**  获得包含当前时间的时间段

      ```
      now_day=pd.Period.now(freq="D")
      now_day   #Period('2021-12-31', 'D')
      ```

      ```
      now_hour=pd.Period.now(freq="H")
      now_hour   #Period('2021-12-31 17:00', 'H')

   2. 获取freq的选值

      ```
      pandas.tseries.frequencies._period_code_map.keys()
      ```

   3. 获取Period对象的终点和起点

      ```
      now_day.start_time   #now_day.start_time
      now_day.end_time   #Timestamp('2021-12-31 23:59:59.999999999')
      ```

3. Timedetla 时间间隔 :   pd.Timedelta() 创建时间间隔Timedelta对象

   1. ```
      td=pd.Timedelta(weeks=2,days=10,hours=12,minutes=2.4,seconds=10.3)
      td
      ```

   2. Timedelta对象有属性：weeks、days、seconds、milliseconds、microseconds和nanoseconds

      ```
      print(td.days)  #24
      print(td.seconds)  #43354
      print(td.microseconds)  #300000
      print(td.nanoseconds)  #0
      ```

4. 三者之间的转换

   1. **to_period()**将时间点Timestamp对象转换为包含该时间点的时间段

      ```
      now.to_period("H")
      ```

   2. 两个时间点Timestamp对象 相减得到 时间间隔Timedelta对象

      ```
      nation_day=pd.Timestamp("2018-10-1")
      td1=nation_day-pd.Timestamp.now()
      td1
      ```

   3. 时间点和时间间隔之间可以进行加减运算

      ```
      nation_day+pd.Timedelta("20 days 10:20:30")
      ```

      

#### 时间序列

1. DatetimeIndex、PeriodIndex和TimedeltaIndex， 都可以作为Series和DataFrame的索引

   1. **pd.date_range()** 创建 DatetimeIndex 序列

      ```
      #时间点序列
      index=pd.date_range("2018-03-17","2018-03-30",freq="2H")
      len_index = len(index)   #157
      loc=np.random.choice(np.arange(len_index),size=4,replace=False)  #随机选取4个互不相同的数
      loc.sort()
      ts_index=index[loc]  #用索引取时间点
      ts_index
      ```

   2. **.to_period()**  将DatetimeIndex序列转换为PeriodIndex序列

      ```
      #时间段序列
      pd_index=ts_index.to_period("D")
      pd_index
      ```

   3. **pd.TimedeltaIndex()**  将DetetimeIndex序列转换为 TimedeltaIndex 序列

      ```
      #时间间隔序列
      longseconds=np.diff(ts_index) #返回array([136800000000000, 554400000000000, 201600000000000], dtype='timedelta64[ns]')
            
      td_index=pd.TimedeltaIndex(longseconds)
      td_index
      ```
      
   4. 三者提供了许多与时间有关的属性

      1. ts_index.weekday
      2. pd_index.month
      3. td_index.days
      4. td_index.seconds

   5. DatetimeIndex.shift()     移动时间点

      1. ts_index.shift(2,"2H")

   6. DatetimeIndex.normalize()    将时刻修改为当天的凌晨零点

      1. ts_index.normalize()

2. 时间序列作 索引

   1. DatetimeIndex, PeriodIndex, TimedeltaIndex都可以作为 Series、Dataframe对象的索引和列.  只介绍  作为Series对象的索引

   2. ```
      ts_series=pd.Series(range(4),index=ts_index)
      ts_series
      ```

   3. ser.between_time()   返回位于指定时间段的数据集

      ts_series.between_time("7:00","17:00")

   4. ser.tshift()   # tshift() 被 shift()代替, 将索引移动指定的时间

      ts_series.tshift(1,"2D")

3. 时间序列 作 Seires的列值

   1. ```
      ts_data=pd.Series(ts_index)
      ts_data
      ```

   2. 属性dt  调用时间属性

      ```
      ts_data.dt.hour

   

   

4. DatetimeIndex :  非常重要的数据类型, 自身有许多方法

   2. `pd.date_range(start=None, end=None, periods=None, freq='D')`    #返回<class 'pandas.core.indexes.datetimes.DatetimeIndex'>类型

      1. DatetimeIndex 时间戳没有重采样函数resample(),  
      2. pd.date_range(start='20170101',end='20170924',freq='BM')
         1. 类型 `pandas.core.indexes.datetimes.DatetimeIndex`
      3. pd.date_range(start='20170101',periods=10,freq='WOM-3FRI')
         1. 类型 `pandas.core.indexes.datetimes.DatetimeIndex`

   3. 频率的缩写

      1. | 别名   | 偏移量类型         | 说明                     |
         | ------ | ------------------ | ------------------------ |
         | D      | Day                | 每日历日                 |
         | B      | BusinessDay        | 每工作日                 |
         | H      | Hour               | 每小时                   |
         | T或min | Minute             | 每分                     |
         | S      | Second             | 每秒                     |
         | L或ms  | Milli              | 每毫秒(即每千分之一秒)   |
         | U      | Micro              | 每微秒(即每百万分之一秒) |
         | M      | MonthEnd           | 每月最后一个日，历日     |
         | BM     | BusinessMonthEnd   | 每月最后一 个工作日      |
         | MS     | MonthBegin         | 每月第一个日历日         |
         | BMS    | BusinessMonthBegin | 每月第一个工作日         |

5. PeriodIndex 时间段

   1. pandas重采样
      1. 将 `时间序列` 从一个频率转化为另一个频率进行处理
      2. 将高频率数据转化为低频率数据为 `降采样`
      3. 低频率转化为高频率为 `升采样`

   2. resample方法, 实现频率转化, (实例方法, 没有类方法)
      1. t.resample('M').mean()
      2. t.resample('10D').count()
      3. t.resample('QS-JAN').count()

      

6. pd读取 `pd.read_csv()`, 存储df1.to_csv('路径/文件名')

   1. ```
      csv_obj = pd.read_csv(filename,usecols = ['countries_en', 'additives_n']).dropna()  #去掉nan所在的行
      
      items = {}
      for i in csv_obj.index:
          if csv_obj['countries_en'][i] in items: # 每一列都是一个Series实例
              items[csv_obj['countries_en'][i]] = float(items[csv_obj['countries_en'][i]]) + float(csv_obj['additives_n'][i])  # 把csv_ob字典的键值重新赋值, DataFrame的列用1,2,3,4等进行索引
          else:
              items[csv_obj['countries_en'][i]] = float(csv_obj['additives_n'][i])
      items
      
      dict_obj = pd.Series(items)
      data = dict_obj.sort_values(ascending=False)
      print(data)
      data.to_csv('newfood.csv')  # to_csv(' ') 保存为to_csv
      
      %matplotlib inline    %matplotlib inline 可以在Ipython编译器里直接使用，功能是可以内嵌绘图，并且可以省略掉plt.show()这一步
      data[:10].plot.bar()
      ```

      

#### 08 DataFrame

1. DataFrame属性 :  **.index**,  **.columns**,  **.values**,  **ndim** ,  **shape**,  **size** ,  **dtypes** ,  **T**

   ndim    返回DataFrame的维数；
   shape   返回DataFrame的形状；
   dtypes  返回DataFrame 每一列元素的数据类型；
   size       返回DataFrame中元素的个数；
   T            返回DataFrame的转置结果；
   index    返回DataFrame中的索引；
   columns 返回DataFrame中的列索引；
   values   返回DataFrame中的数值；
   
2. pd.DataFrame() 创建

   1. np.ndarray 创建 DataFrame

      1. `df1=pd.DataFrame(np.arange(12).reshape((3,4)))`

   2. dict创建DataFrame

      1. ```
         dic = {
             "A" : 1,
             "B" : pd.Timestamp("20170426"),
             "C" : pd.Series(range(10, 14), dtype = "float64"),
             "D" : ["Python", "Java", "C++", "C"],
             "E" : np.array([3] * 4, dtype="int32"),
             "F" : "ITCast"
         }
         df1 = pd.DataFrame(dic)
         print(df1)
         ```

         1. 输出

            ```
               A          B     C       D  E       F
            0  1 2017-04-26  10.0  Python  3  ITCast
            1  1 2017-04-26  11.0    Java  3  ITCast
            2  1 2017-04-26  12.0     C++  3  ITCast
            3  1 2017-04-26  13.0       C  3  ITCast
            ```

         2. 列索引, `df1['B']`   #输出B列元素, type(df1['B']) 是 pandas.core.series.Series

         3. 行用切片获取, 不要行索引获取. `df1[0]`, `df1['0']`  #都报错

3. DataFrame取元素 取 一列 或 一个元素

   1. `[列索引]` 取列得 Series, `[列索引][行索引]` 取元素

      1. 必须: 先取列，再取行.  定位 DataFrame对象的元素

         1. `df1['D'][2]`  # C++, 数值类型索引 不用引号, 字符串类型索引用引号
         2. `df1.D[2]`   #C++

      2. 增加一列

         1. `df1['G'] = df1['C'] + 10`

            1. 输出

               ```
                  A          B     C       D  E       F     G
               0  1 2017-04-26  10.0  Python  3  ITCast  20.0
               1  1 2017-04-26  11.0    Java  3  ITCast  21.0
               2  1 2017-04-26  12.0     C++  3  ITCast  22.0
               3  1 2017-04-26  13.0       C  3  ITCast  23.0
               ```

            2. `type(df1['G'])`  #pandas.core.series.Series

      3. 删除 一列 :  `del(df1['E'])`   #删除列'E'

4. pandas之 布尔索引:  `df1[df1['E']>2]`   #df1['E']>2 返回 bool元素的<class 'pandas.core.series.Series'>类型

   1. 布尔逻辑:   `&`  与,   `| `或,   

      df1[ (df1['E']>2) & (df1['C']==11.0)]

5. pandas之 `loc` 标签索引, `iloc` 序号(index)索引

   1. 数据 :  `df1 = pd.DataFrame([[0,1,2,3],[4,5,6,7],[8,9,10,11]],index=['A','B','C'],columns=['W','X','Y','X'])`

      1. 输出

         ```
            W  X   Y   X
         A  0  1   2   3
         B  4  5   6   7
         C  8  9  10  11
         ```

   2. 标签索引: 方式:`df1.loc[[行标签], [列标签列表]]`

      1. `df1.loc[[行标签列表]]`
      2. `df1.loc[['A','C'],["W",'X']]`   #输出类型 `pandas.core.frame.DataFrame`
      3. `df1.loc['A','W']`   #返回<class 'numpy.int64'>

   3. 类型: 

      1. type(df1.loc[['A'],['W']])   #<class 'pandas.core.frame.DataFrame'>
      2. type(df1.loc['A','W'])   #<class 'numpy.int64'>
      3. type(df1.index)   #pandas.core.indexes.base.Index
      4. type(df1.columns)  #pandas.core.indexes.base.Index
      5. `type(df1.loc[['A'],['W','X']])`   #<class 'pandas.core.frame.DataFrame'>

   4. 切片

      1. `df1.loc['A':,['W','X']]`   #切片, 切片是一个list类型
      2. `df1.loc['A':'C',['W','X']]`   #切片

6. 位置序号索引: 方式:  `iloc[[行序号], [列序号]]`  获取数据  

   1.  示例
      1. `df1.iloc[1:5,[2,3]]` ;   `df1.iloc[1:3,1:3]`
   
   2.  修改, 增加数据, 标签索引,序号索引号 都可以
   
         1. `df1.loc[['A'],['Y']] = 100`
   
         1. `df1.iloc[1:2,0:2] = 200`
   
7. pandas 缺失数据 `NaN`,  pandas缺失值 是`NaN`, 表示 空 None.  numpy缺失值是 `np.nan`

   1. pandas判断缺失元素, (实例方法, 类方法)
      1. `pd.isnull(df1)` ,   `pd.isna(df1)` ,  `pd.notnull(df1)` ,`pd.notna(df1)`
      2. `pd1.isnull()` , `pd1.notnull()` , `pd1.isna()` , `pd1.notna()`
   
   2. dropna() 删除NaN所在的行/列
      1. `pd1.dropna (axis=0, how='any', inplace=False)`  #实例方法, 没有类方法
      2. 没有 dropnull 方法
   
   3. fillna() 填充, (实例方法, 没有类方法)
      1. `pd1.fillna(df1.mean())`  #其他填充值 : `df1.median()`,  或 `0`
   
      1. `0` 与 `NaN`,  `NaN` 不参与计算, `0` 参与计算
   
8. pandas 统计方法

   1. `pd1['W'].mean()`
   2. `pd1['W'].max()`
   3. `pd1['W'].argmax()`
   4. `pd1['W'].min()`
   5. `pd1['W'].argmin()`
   6. `pd1['W'].median()`
   7. `pd1['W'].tolist()`
   8. `list(set(pd1['W']))`  #去重, 还有 pd.drop_duplicates()

9. 索引和复合索引

   1. `pd1.index`  #获取索引
   1. 设定 索引
      1. `pd1.index = ['x','y']`  #指定index , 个数与原来相同
      2. `pd1.reindex(list("abcedf"))`    #重新设置index 
         1. list("abcedf")  #['a', 'b', 'c', 'e', 'd', 'f']
      3. `pd1.set_index(["W"],drop=False) ` #指定DataFrame中 某列 或 几列 作为index , drop默认是True
         1. drop 作索引的列要不要删除
   2. loc[] 
      1. `df1.loc['a']`    #取行a, 返回DataFrame数据
      2. `df1.loc['a'].loc['W']`  #'a'行标签, 'W'列标签

10. pandas 索引的切片

   11. Series 索引 (标签索引, 序号索引)

       1. 数据: ser1 = pd.Series(range(10, 15), index = ["a", "b", "c", "d", "e"])
       2. 切片: `ser1['a':'c']`  #标签索引;    `ser1[1:4]`   #序号索引
       3. 标签索引 列表 : `ser1[['a','c']]`
       4. 序号索引 列表: `ser1[[1,4]]`
       5. bool索引
          1. `ser1[ser1>11]`
          2. `ser1[ser1<12]`
          3. `ser1[(ser1>11) & (ser1 <14)]`   #与运算
          4. `ser1[(ser1>13) | (ser1 <11)] `   #或运算
       6. loc[] 标签切片: `ser1.loc['a':'c']`
       7. iloc[] 序号切片 :  `ser1.iloc[1:3]`
       8. 小结
          1.  Series 没有 `.ix[]`

   12. DataFrame索引

       1. ````
          df1 = pd.DataFrame(
                           np.random.rand(5, 5),
                           index = ["a", "b", "c", "d", "e"],
                           columns = ['A', 'B','C','D','E']
                       )
          ````
          
          输出:

          ```
                    A         B         C         D         E
          a  0.516787  0.669657  0.549715  0.020292  0.380318
          b  0.599049  0.079925  0.425783  0.266294  0.998097
          c  0.156863  0.472687  0.089392  0.170414  0.174902
          d  0.763683  0.860909  0.589888  0.280977  0.844625
          e  0.401372  0.415432  0.107797  0.249938  0.855987
          ```
          
       2. [] 切片:  `[行标签切片]` , `[行序号切片]`,  没有 列索引切片

          1. df1['a':'c']   #行标签索引切片
          2. df1[ 2: 4]   #行标签索引切片
          3. 备注
             1.  DataFrame数据没有列切片 ( 没有列标签索引切片, 没有 列序号索引切片), 有单列 取值, 多列 取值
                1. 即 df1[:, 'A':'C'],  df1[:, 1:3] 报错
                2. df1[['A'] ] #取'A'列值
                3. df1[['A','C']]  #取 'A', 'C' 两列的值
             2. DataFrame 有行切片( 行标签索引切片, 行序号索引切片). 没有单 行标签索引 取值, 没有单 行序号索引 取值
                1. 即 df['a'], df[0] ,#报错,  'a' 行标签, 0 行序号
                2. df1['A':'C'],   #行标签索引切片 `'A':'C'` 对应的 DataFrame
                3. df1[1:3]   #行序号索引切片 `1:3` 对应的 DataFrame
       
       3. `loc[]` : 行标签 切片,  行标签切片 组合 列标签切片, 没有单独的列切片

          1. df1.loc['a':'c']  #标签索引切片
          2. df1.loc['a':'c, 'A':'C']   # 行标签索引切片 组合 列标签切片
       
       4. `iloc[]` :  行序号 切片, 行序号 切片 组合 列序号切片, 没有单独的列切片
          
          1. df1.iloc[2:4]  #行序号索引切片
          2. df1.iloc[2:4, 2:3]   #行序号索引切片 组合 列序号切片
       
       
       

#### 09 统计方法和字符串离散化

1. 数据:  df1 = pd.DataFrame([[1,2,3,4],[2,3,4,5],[6,7,8,9],[7,8,9,10]], columns = ["a", "b", "c", "d"])

2. `df1. sum(axis=1)`  # 统计和

   1. ```
      0    10
      1    14
      2    30
      3    34
      dtype: int64
      ```

   2. axis 指定 轴方向

      1. 默认是0, 统计列, (各行的 同一列  元素统计)
      2. 1 是统计行,  (各列的 同一行 元素统计)

3. `df1.min()`    #统计最小值

4. df1.describe()    #数据描述

#### 10 分组, 聚合, 合并,四则运算

1. 数据

   1. ```
      import pandas as pd
      import numpy as np
      dict_obj = {'key1' : ['a', 'b', 'a', 'b', 'a', 'b', 'a', 'a'],
                          'key2' : ['one', 'one', 'two', 'three','two', 'two', 'one', 'three'],
                  'data1': np.random.randn(8),
                  'data2': np.random.randn(8)}
      df1 = pd.DataFrame(dict_obj)
      df1
      ```

      输出:

      ```
        key1   key2     data1     data2
      0    a    one -1.020289 -0.880800
      1    b    one  0.287934 -0.517303
      2    a    two -1.163154 -0.187739
      3    b  three -0.733823 -0.990685
      4    a    two -0.352747  0.388376
      5    b    two -0.565068 -0.458437
      6    a    one -0.573826 -0.415826
      7    a  three  1.470366 -1.188190
      ```

      输入: 

      ```
      b=df1.groupby('key1')
      b.dtypes  #每个元素的类型
      ```

      输出:

      ```
              key2    data1    data2
      key1                          
      a     object  float64  float64
      b     object  float64  float64
      ```

   

1. 分组  groupby()

   1. grouped=df1.groupby(by="columns_name")   #分组工具

      1. 参数: by参数 指定分组列名, 对整个数据集分组，

      2. 返回类型 `<class 'pandas.core.groupby.generic.DataFrameGroupBy'>` 对象, 可迭代的

         1. 每一个元素是一个元组 (name, data)

         2. ```
            
            #DataFrameGroupBy对象 是可迭代的, 迭代操作 for...in...
            for name, data in grouped:
            	print(name)
            	print(data)
            ```

      3. ```
         from collections import Iterable
         from collections import Iterator
         isinstance(i, Iterator)
         ```

         

   2. `.add_prefix('sum_')`  列标签添加 前缀  `sum_`

      1. df1_grouped_sum_pre = df1.groupby("key2").sum().add_prefix('sum_')

      2. 输出结果

         ```
             sum_data1  sum_data2  sum_ABC
         key2                                
         one     1.866829   2.700305       10
         three  -1.331977  -1.033251       12
         two    -2.781120  -1.953212       14
      
   3. 分组 方法

      1. 对所有数据 按列分组
         
         1. ```
            df1_grouped_sum = df1.groupby("key2").sum()  # 列标签"key2"
            
            #添加一新列数据
            df1['ABC'] = [1,2,3,4,5,6,7,8]
            df1
            
            #新加的新列对之前的分组没有影响
            df1_grouped_sum
            ```
            
            
         
      2. 对某列 按指定列 分组，groupby参数指定列分组
   
         1. df1['key2'].groupby(df1['key1'])
   
      3. 按 数据类型 分组
   
         1. df1.groupby(df1.dtypes, axis=1)
   
      4. 多重 分组, `df1_group = df1.groupby(['key1', 'key2'])`
   
         1. 列表参数 决定
   
      5. 按 层级名 分组
   
         1. ```
            #定义多层列标签: 列标签 和 列标签的层级名
            df1_col_label = pd.MultiIndex.from_arrays([['Python', 'Java', 'Python', 'Java', 'Python'], ['A', 'A', 'B', 'C', 'B']], names=['level_col1', 'level_col2']) #参数1指定第一阶 第二阶列标签, names指定第一阶列标签名, 第二阶列标签名
            
            #定义数据, 指定列标签
            df1= pd.DataFrame(np.random.randint(1, 10, (5, 5)), columns=df1_col_label )
            df1
            
            #按 阶级名 分组
            df1.groupby(level ="level_col1", axis=1).sum()
            
            df1.groupby(level ="level_col2", axis=1).sum()
            ```

      6. 自定义分组列: list, 或 dict
   
         ```
         dict_obj = {'key1' : ['a', 'b', 'a', 'b', 'a', 'b', 'a', 'a'],
                             'key2' : ['one', 'one', 'two', 'three','two', 'two', 'one', 'three'],
                     'data1': np.random.randn(8),
                     'data2': np.random.randn(8)}
         df1 = pd.DataFrame(dict_obj)
         ```
   
         1. 按自定义列表 分组
   
            1. ```
               #自定义的分组列, 
               group_rule = ["aa", "aa", "cc", "dd", "aa", "aa", "cc", "dd"]
               grouped3 = df1.groupby(group_rule)
               grouped3.sum()
               ```
               
               1. group_rule 列表长度等于数据行数
         
         2. 按自定义 字典 分组, 键 为行索引, 值为分组后index行索引
         
            1. ```
               df1 = pd.DataFrame(np.random.randint(1, 10, (5,6)),columns=['A', 'B', 'C', 'D', 'E','F'],index=['a', 'b', 'c', 'd', 'e'])
               df1.iloc[1, 1:4] = np.NaN
               df1
               ```
         
            2. ```
               #键 为行索引, 值为分组后index行索引. 自定义的分组列
               dic_rule = {"a" : "C++", "b": "Python", "c" : "Java", "d" : "PHP", "e" : "C++"}
               df1.groupby(dic_rule, axis = 0).size()  #返回<class 'pandas.core.series.Series'>类型
               ```
               
            3. 输出结果
   
               1. ```
                  C++       2
                  Java      1
                  PHP       1
                  Python    1
                  dtype: int64
                  ```
         
                  
         
         3. 按自定义函数 分组
         
            1. ```
               def group_func(idx):  #axis=1则idx行索引,axis=0则idx 列索引
                   return len(idx)
               df1.groupby(group_func, axis=1).sum()
               ```
   
2. agg(), transform() 两种聚合方法

   1. agg(聚合函数名) : 聚合操作 

      1. `groupby` 分组后用 agg() 对 `numeric types` 数据 基于`列`的聚合操作

      2. 聚合函数 

         2. | 聚合函数      | 说明                                     |
            | ------------- | ---------------------------------------- |
            | count()       | 分组中非 `NA` 值的数量. 对每一个数据标记 |
            | sum()         | 每一组的 非 NA 值的和                    |
            | mean()        | 每一组的 非 NA 值的平均值                |
            | median()      | 每一组的 非NA值的算术中位数              |
            | std(),  var() | 无偏(分母为n-1)标准差, 方差              |
            | min(), max()  | 非NA值的最小值, 最大值                   |
            | size()        | 统计每一组的个数                         |
         
            1. `df.groupby(by=["Country","State/Province"])["Country"].count()`
   
      3. 数据
   
         1. ```
            data_dict= {'key1' : ['a', 'b', 'a', 'b', 'a', 'b', 'a', 'a'],
                        'key2' : ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],
                        'key3' : ['one2', 'one2', 'two2', 'three2', 'two2', 'two2', 'one2', 'three2'],
                        'data1': [1,2,3,4,5,6,7,8],
                        'data2': [11,12,13,14,15,16,17,18]}
            #All arrays must be of the same length
            df1 = pd.DataFrame(data_dict)
            ```
   
      4. 内置聚合函数
   
         1. `df1.groupby("key1").sum()`,  或`df1.groupby('key1').agg('sum')`
         2. `df1.groupby("key1").max()`,  或`df1.groupby('key1').agg('max')`
         3. `df1.groupby("key1").min()`,  或`df1.groupby('key1').agg('min')`
         4. `df1.groupby("key1").mean()`,  或`df1.groupby('key1').agg('mean')`
         5. `df1.groupby("key1").describe()`,  或`df1.groupby('key1').agg('describe')`

      5. 自定义聚合函数
   
         1. ```
            def func(num):
                return num.max() - num.min() 
            df1.groupby("key1").agg(func)
            ```

            1. 以 `key1` 进行分组, 对每组的应用 func函数
   
            2. 返回值类型: `pandas.core.frame.DataFrame`
   
            3. ```
                     data1  data2
               key1              
               a         7      7
               b         4      4
               ```
   
      6. 多个聚合函数
   
         1. df1.groupby("key1").agg(["sum", "mean", "max", func])
   
            1. 返回值类型 `pandas.core.frame.DataFrame`

            2. 返回值

               1. ```
                       data1               data2               
                         sum mean max func   sum  mean max func
                  key1                                         
                  a       24  4.8   8    7    74  14.8  18    7
                  b       12  4.0   6    4    42  14.0  16    4
                  ```
   
      7. 列标签指定聚合函数
   
         1. ```
            agg_func = {'data1':'mean','data2':'sum'} #元素是 列标签:聚合函数名
            df1.groupby('key1').agg(agg_func)
            ```
   
         2. ```
                data1  data2
            key1              
            a       4.8     74
            b       4.0     42
            ```
         
      8. 一列多个聚合函数
   
         1. ```
            agg_func = {'data1':'mean','data2':['sum', 'mean', func]}  #元素是 列标签:聚合函数名
            df1.groupby('key1').agg(agg_func)
            ```
      
            1. 返回值类型 `pandas.core.frame.DataFrame`
   
         2. ```
                data1 data2           
                 mean   sum  mean func
            key1                       
            a      4.8    74  14.8    7
            b      4.0    42  14.0    4
            ```
      
   2. transform('聚合函数名')  聚合操作: 运算结果和原始数据 形状一致, 不改变原表形状
   
      1. 数据
   
         ```
         data_dict = {'key1' : ['a', 'b', 'a', 'b',  'a', 'b', 'a', 'a'],
                             'key2' : ['one', 'one', 'two', 'three', 'two', 'two', 'one', 'three'],
                            'data1': np.random.randint(1, 10, 8),
                            'data2': np.random.randint(1, 10, 8)}
         df1 = pd.DataFrame(data_dict)
         ```
   
         1. ```
            key1   key2  data1  data2
            0    a    one      1      1
            1    b    one      3      1
            2    a    two      5      4
            3    b  three      8      8
            4    a    two      7      9
            5    b    two      7      7
            6    a    one      9      8
            7    a  three      5      6
            ```
   
            
   
      2. transform聚合 示例
   
         1. df1.groupby('key2').transform('sum')   #对每个分组用聚合
   
            1. ```
            key1 data1 data2
               0  aba    13    10
               1  aba    13    10
               2  aab    19    20
               3   ba    13    14
               4  aab    19    20
               5  aab    19    20
               6  aba    13    10
               7   ba    13    14
               ```
         
            1. 其他 `max, min, count`等等
   
            1. df1.groupby('key2').describe()
   
         2. 自定义函数
         
            1. ```
               def func(df):
                   return df.sum()
                   
               #分组,聚合,添加前缀, 保存
               df_grouped_trans = df1.groupby("key1").transform(func).add_prefix("newsum_")
               
               #添加新列
               df1[df_grouped_trans.columns] = df_grouped_trans 
               df1
               ```
         
               1. ```
                  #输出结果
                    key1   key2  data1  data2        newsum_key2 newsum_data1 newsum_data2
                  0    a    one      1      1  onetwotwoonethree           27           28
                  1    b    one      3      1        onethreetwo           18           16
                  2    a    two      5      4  onetwotwoonethree           27           28
                  3    b  three      8      8        onethreetwo           18           16
                  4    a    two      7      9  onetwotwoonethree           27           28
                  5    b    two      7      7        onethreetwo           18           16
                  6    a    one      9      8  onetwotwoonethree           27           28
                  7    a  three      5      6  onetwotwoonethree           27           28
                  ```
      
      

3. 合并与连接,

   1. pandas 连接方法有 merge, join, concat

      1. pandas的 merge方法是合并,   实现了 sql 的 join方法。
      2. pandas的 join 方法，相比merge，只是个弟弟，使用场景有限。
      3. pandas的 concat 实现两个 df 按行或列简单拼接, 没有实现 sql 的 join 功能
      
   2. pd.merge() :  两种合并: 表1 表2 上下合并, 表2 表2 左右合并

      1. 数据

         1. ```
            df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'],'data1' : np.random.randint(0,10,7)})
            df2 = pd.DataFrame({'key': ['a', 'b', 'd'],'data2' : np.random.randint(0,10,3)})
            ```

            df1:

            ```
              key  data1
            0   b      4
            1   b      8
            2   a      6
            3   c      9
            4   a      6
            5   a      4
            6   b      3
            ```

            df2:

            ```
              key  data2
            0   a      3
            1   b      3
            2   d      4
            ```

         2. 行索引 改名: 键是index , 值是新index;  列标签 改名:键是原标签 , 值是新标签

            `df1=df1.rename(columns={"key" : "key1",'data1':'data11'},index={0:'a',3:'c'})`
            
            ```
              key1  data11
            a    b       8
            1    b       8
            2    a       1
            c    c       9
            4    a       8
            5    a       1
            6    b       9

      2. pd.merge(df1, df2)   :  默认内连接, 共有的列取值保留

         1. 默认同列名为合并键, 多列同名则多列合并. 没有同名列标签则报错

            1. ```
                 key  data1  data2
               0   b      3      5
               1   b      7      5
               2   b      7      5
               3   a      1      3
               4   a      4      3
               5   a      9      3
               ```
            
         2. 指定 连接键: pd.merge(df1, df2, on='key')
         
            1. ```
                 key  data1  data2
               0   b      3      5
               1   b      7      5
               2   b      7      5
               3   a      1      3
               4   a      4      3
               5   a      9      3
               ```
         
      3. 左右连接, `merge()` 与 `how` 参数, 表1与表2 左右合并连接

         1. pd.merge() 与 how 配合实现 sql 的 join 功能

         2. 数据

            1. ```
               df1 = df1.rename(columns={"key" : "key1"}) #列标签key改为 key1
               df2 = df2.rename(columns={"key" : "key2"}) #列标签key改为 key2
               ```

            2. ```
               #df1:
                 key1  data1
               0    b      4
               1    b      8
               2    a      6
               3    c      9
               4    a      6
               5    a      4
               6    b      3
               ```

            3. ```
               #df2
                 key2  data2
               0    a      3
               1    b      3
               2    d      4
               ```

         3. 内连接(默认inner),  left_on 左表合并键, right_on 右表合并键, `how=inner`
            1. pd.merge(df1, df2, left_on='key1', right_on='key2', how='inner')   #how='inner'

            2. ```
               #结果
                 key1  data1 key2  data2
               0    b      4    b      3
               1    b      8    b      3
               2    b      3    b      3
               3    a      6    a      3
               4    a      6    a      3
               5    a      4    a      3
               ```

            3. 小结

               1. 列并集,不去重
               2. 左右表连接键交集的 笛卡尔积

         4. 外连接, `outer`

            1. pd.merge(df1, df2, left_on = "key1", right_on = "key2", how ='outer')

               1. ```
                    key1  data1 key2  data2
                  0    b    3.0    b    5.0
                  1    b    7.0    b    5.0
                  2    b    7.0    b    5.0
                  3    a    1.0    a    3.0
                  4    a    4.0    a    3.0
                  5    a    9.0    a    3.0
                  6    c    5.0  NaN    NaN
                  7  NaN    NaN    d    0.0
                  ```

         5. 左连接, `left`, 左表保留

            1. `pd.merge(df1, df2, left_on = "key1", right_on = "key2", how ='left')`

               1. ```
                    key1  data1 key2  data2
                  0    b      3    b    5.0
                  1    b      7    b    5.0
                  2    a      1    a    3.0
                  3    c      5  NaN    NaN
                  4    a      4    a    3.0
                  5    a      9    a    3.0
                  6    b      7    b    5.0
                  ```

         6. 右连接, `right`,  右表保留

            1. `pd.merge(df1, df2, left_on = "key1", right_on = "key2", how ='outer')`

               1. ```
                    key1  data1 key2  data2
                  0    b    3.0    b      5
                  1    b    7.0    b      5
                  2    b    7.0    b      5
                  3    a    1.0    a      3
                  4    a    4.0    a      3
                  5    a    9.0    a      3
                  6  NaN    NaN    d      0
                  ```

         7. 合并操作: 同名列标签添加 后缀

            1. 表1  表2中同名的列标签 添加后缀, 不同名的不添加后缀

            2. 数据

               1. ```
                  df1 = pd.DataFrame({'key': ['b', 'b', 'a', 'c', 'a', 'a', 'b'], 'data' : np.random.randint(0,10,7)})
                  
                  df2 = pd.DataFrame({'key': ['a', 'b', 'd'], 'data': np.random.randint(0,10,3)})
                  ```
                  
               2. <table>
                      <tr><td>df1</td><td>df2</td></tr>
                      <tr><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;key&nbsp;&nbsp;  data<br/>
                  0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4<br/>
                  1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br/>
                  2   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7<br/>
                  3   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;c     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7<br/>
                  4   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7<br/>
                  5   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;6<br/>
                  6   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;7</td><td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;key&nbsp;&nbsp;  data<br/>
                  0   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3<br/>
                  1   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;9<br/>
                  2   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1</td></tr>
                  </table>
                  
                  

            3. 指定连接键，用 `suffixes` 为同名列标签添加 后缀

               1. `pd.merge(df1, df2, on = "key", suffixes = ("_left", "_right"))`

                  1. ```
                         key  data_left  data_right
                     0   b          3           1
                     1   b          9           1
                     2   b          6           1
                     3   a          8           7
                     4   a          9           7
                     5   a          7           7
                     ```

            4. 注意: `.add_prefix("abc")`  所有的列名前都添加abc

   3. pd.concat()   : 相同字段的数据进行首尾连接

      1. pandas.concat() 示例

         1. Series 类型

            1. ```
               ser1 = pd.Series([5,6,0,9,6],index=[0,1,2,3,4])
               ser2 = pd.Series([9,6,5,3], index=[4,5,6,7])
               ser3 = pd.Series([7,4,5], index=[4,7,9])
               ```
               
            2. axis =0 列连接, 三个列连成1个列, 返回类型 pandas.core.series.Series
      
               1. pd.concat([ser1, ser2, ser3],axis=0,join='outer')
      
                  1. ```
                     0    5
                     1    6
                     2    0
                     3    9
                     4    6
                     4    9
                     5    6
                     6    5
                     7    3
                     4    7
                     7    4
                     9    5
                     dtype: int64
                     ```
            
                  3. 默认外连接`outer`
      
                  4. 相同索引保留, 不去重
      
               2. pd.concat([ser1, ser2, ser3],axis=0,join='inner')

                  1. 与 `outer` 一样的结果

            3. axis=1 连接,三列并排变成3个列, 返回类型 pandas.core.frame.DataFrame

               1. outer外连接, 保留所有的数据, pd.concat([ser1, ser2, ser3],axis=1,join='outer')

                  1. ```
                         0    1    2
                     0  5.0  NaN  NaN
                     1  6.0  NaN  NaN
                     2  0.0  NaN  NaN
                     3  9.0  NaN  NaN
                     4  6.0  9.0  7.0
                     5  NaN  6.0  NaN
                     6  NaN  5.0  NaN
                     7  NaN  3.0  4.0
                     9  NaN  NaN  5.0
                     ```
            
                  3. 缺的值 补充`NaN`
            
               2. inner内连接, 保留共有的index的值,  pd.concat([ser1, ser2, ser3],axis=1,join='inner')
      
                  1. ```
                        0  1  2
                     4  6  9  7
                     ```
               
                  2. 返回类型 pandas.core.frame.DataFrame
            
         2. DataFrame 数据
      
            1. ```
               df1 = pd.DataFrame([[1, 2],[3, 4],[5,6]], index=['a', 'b', 'c'],columns=['A', 'B'])
               df2 = pd.DataFrame([[1,2],[7,8]], index=['a', 'b'],columns=['B', 'C'])
               ```
               
               1. ```
                  #df1
                     A  B
                  a  4  7
                  b  0  7
                  c  4  7
                  
                  #df2
                     B  C
                  a  6  5
                  b  0  1
                  ```
               
            2. axis = 0
      
               1. outer: 保留所有数据, 填充NaN, pd.concat([df1, df2],axis=0,join='outer')
      
                  1. ```
                          A  B    C
                     a  1.0  2  NaN
                     b  3.0  4  NaN
                     c  5.0  6  NaN
                     a  NaN  1  2.0
                     b  NaN  7  8.0
                     ```
            
               2. inner: 保留共有列字段的数据,  pd.concat([df1, df2],axis=0,join='inner')
            
                  1. ```
                           B
                     a  2
                     b  4
                     c  6
                     a  1
                     b  7
                     ```
            
            3. axis = 1
            
               1. outer: 保留所有数据, pd.concat([df1, df2], axis=1, join='outer')
      
                  1. ```
                           A  B    B    C
                     a  1  2  1.0  2.0
                     b  3  4  7.0  8.0
                     c  5  6  NaN  NaN
                     ```
            
               2. inner: 保留共有行索引的数据,  pd.concat([df1, df2], axis=1, join='inner')
            
                  1. ```
                           A  B  B  C
                     a  1  2  1  2
                     b  3  4  7  8
                     ```
      
   4. 补充: Numpy 数组连接 之 concatenate( ) 
   
      1. ```
      arr1 = np.random.randint(0, 10, (3, 4))
         arr2 = np.random.randint(0, 10, (3, 4))
         ```
         
         1. ```
         #arr1
            array([[1, 4, 4, 3],
                   [8, 1, 1, 4],
                   [4, 1, 4, 4]])
            ```
         
         2. ```
            #arr2
            array([[0, 6, 4, 9],
                   [6, 9, 9, 9],
                   [3, 9, 1, 0]])
            ```
         
            

      2. `np.concatenate( )` 方法连接 示例
   
         1. `a1=np.concatenate([arr1, arr2])`
   
            1. 默认 axis=0 轴 纵向拼接
   
            2. ```
               array([[1, 4, 4, 3],
                      [8, 1, 1, 4],
                      [4, 1, 4, 4],
                      [0, 6, 4, 9],
                      [6, 9, 9, 9],
                      [3, 9, 1, 0]])
               ```
      
         2. `a2=np.concatenate([arr1, arr2], axis=1)`
   
            1. `1`轴, 横向拼接
   
      3. np 没有 concate() 函数
   
4. pandas 四则运算

   1. Series add() 加( 表1 加 表2)

      1. 数据

         1. ```
            import pandas as pd
            import numpy as np
            ser1 = pd.Series(range(10, 20), index = (range(10)))
            ser2 = pd.Series(range(10, 15), index = (range(5)))
            ```

            1. ```
               #ser1
               0    10
               1    11
               2    12
               3    13
               4    14
               5    15
               6    16
               7    17
               8    18
               9    19
               dtype: int64
               ```

            2. ```
               #ser2
               Out[98]: 
               0    10
               1    11
               2    12
               3    13
               4    14
               dtype: int64
               ```

      2. add()

         1. `ser1.add(ser2)`

            1. ```
               0    20.0
               1    22.0
               2    24.0
               3    26.0
               4    28.0
               5     NaN
               6     NaN
               7     NaN
               8     NaN
               9     NaN
               dtype: float64
               ```

            2. 默认 fill_value=np.nan

               1. index共同有值的相加, index中有一列缺值的 赋为`NaN`

      3. add() 相加, 填充值

         1. `ser1.add(ser2, fill_value=0)`

            1. fill_value 参数 将Series对象中没有inde的数据， 填充为指定值，一般都指定为0，避免运算误差

            2. ```
               0    20.0
               1    22.0
               2    24.0
               3    26.0
               4    28.0
               5    15.0
               6    16.0
               7    17.0
               8    18.0
               9    19.0
               dtype: float64
               ```

   2. DataFrame  add() 加, 

      1. 数据

         1. ```
            df1 = pd.DataFrame(np.ones((2,2)), columns = ['a', 'b'])
            df2 = pd.DataFrame(np.ones((3,3)), columns = ['a', 'b', 'c'])
            ```

            1. df1

               1. ```
                       a    b
                  0  1.0  1.0
                  1  1.0  1.0
                  ```

            2. df2

               1. ```
                       a    b    c
                  0  1.0  1.0  1.0
                  1  1.0  1.0  1.0
                  2  1.0  1.0  1.0
                  ```

      2. add() 方法

         1. `df1.add(df2)`

            1. ```
                    a    b   c
               0  2.0  2.0 NaN
               1  2.0  2.0 NaN
               2  NaN  NaN NaN
               ```

            2. 有值的相加,  fill_value缺值的 赋为`NaN`

      3. add, 加 参数 fill_value

         1. `df1.add(df2, fill_value=0)`

            1. ```
                 a    b    c
               0  2.0  2.0  1.0
               1  2.0  2.0  1.0
               2  1.0  1.0  1.0
               ```
      
   3. Series, DataFrame的对象的其他 数学计算

      1. sub(), div(), mul() ，分别 对应 减、除、乘

5. 标签索引 层级

   1. 数据

      1. ```
         # 三层索引, 字母, 数字
         
         ser1 = pd.Series(np.random.randn(12), index = [
             ['a', 'c', 'b', 'a', 'b', 'c', 'b', 'c', 'a', 'c', 'a', 'b'],
             [-10, -1, 11, 0, -1, 21, 10, 11, 21, -11, 18, 26],
             [10, 12, 25, 20, 14, 20, 2, 12, 11, 9, -10, 0]
         ])
         ```

         1. ```
            a  -10   10    0.903096
            c  -1    12   -1.503659
            b   11   25   -0.041711
            a   0    20   -1.354742
            b  -1    14    0.986028
            c   21   20    0.754251
            b   10   2     0.059569
            c   11   12    0.036387
            a   21   11    1.476968
            c  -11   9     2.055948
            a   18  -10   -1.394747
            b   26   0     0.446518
            dtype: float64
            ```

      2. ser1.index

         1. 返回值类型 `pandas.core.indexes.multi.MultiIndex`
         
         2. 返回值
         
            1. ```
               MultiIndex([('a', -10,  10),
                           ('c',  -1,  12),
                           ('b',  11,  25),
                           ('a',   0,  20),
                           ('b',  -1,  14),
                           ('c',  21,  20),
                           ('b',  10,   2),
                           ('c',  11,  12),
                           ('a',  21,  11),
                           ('c', -11,   9),
                           ('a',  18, -10),
                           ('b',  26,   0)],
                          )
               ```

   2. 按层取值

      1. 外层

         1. `ser1['b']`

            1. 返回值类型 `pandas.core.series.Series`
            
            2. ```
               11  25   -0.041711
               -1   14    0.986028
                10  2     0.059569
                26  0     0.446518
               dtype: float64
               ```

      2. 中间层

         1. `ser1[:, 21]`

            1. ```
               c  20    0.754251
               a  11    1.476968
               dtype: float64
               ```

      3. 最内层

         1. `ser1[:, :, 12]`

            1. ```
               c  -1    -1.503659
                   11    0.036387
               dtype: float64
               ```

      4. 取一个值

         1. `ser1['b',10, 2]`
            1. 返回值类型 `numpy.float64`
            2. `0.05956858189336576`

   4. `ser1.swaplevel()`   不同层的 索引交换

      1. 默认最外层和最内层做交换
      2. 参数:  0 最外层 , 1 中间层, 2 最内层
      3. ser1.swaplevel(0,2)
      
   5. sort_index()  #默认是升序, ascending=False 指定为降序, 按不同层的索引排序
   
      1. `ser1.sort_index(level=2, ascending=False))`
   
7. 数据结构转换

   1. 数据的层次化结构有两种: 表结构 , 花括号结构
   1. 一种是表格, 行列上均有索引
      2. 一种是“花括号” , 只“列方向”上的索引
      
   2. unstack()  , stack() 介绍

      1. 层次化索引
      1. 是 python进 层次化索引。
         2. 对索引 层次化分类，便于使用
         3. 索引 是行索引，或 列索引
      2. 两层及以上 Series结构 与 DataFrame结构 的转换

   4. 数据

      1. ```
      # 三层索引, 字母, 数字

         ser1 = pd.Series(np.random.randn(12), index = [
             ['a', 'c', 'b', 'a', 'b', 'c', 'b', 'c', 'a', 'c', 'a', 'b'],
             [-10, -1, 11, 0, -1, 21, 10, 11, 21, -11, 18, 26],
             [10, 12, 25, 20, 14, 20, 2, 12, 11, 9, -10, 0]
         ])

         ```

   4. unstack()  

      1.  Series变成DataFrame, 即 从 `花括号` 变成 `表`结构

      2. `ser_to_df = ser1.unstack(0)`

         1. 参数 是 index 的层 0, 1, 2

         2. ```
         #输出 ser_to_df
                            a         b         c
            -11  9        NaN       NaN  0.286925
            -10  10  0.866547       NaN       NaN
            -1   12       NaN       NaN  1.021504
                 14       NaN  1.188193       NaN
             0   20 -0.700148       NaN       NaN
             10  2        NaN  0.695750       NaN
             11  12       NaN       NaN  0.953382
                 25       NaN -1.137258       NaN
             18 -10  0.265473       NaN       NaN
             21  11  1.245911       NaN       NaN
                 20       NaN       NaN  0.245710
             26  0        NaN -0.618138       NaN
            ```

         3. 返回 pandas.core.frame.DataFrame 类型

   5. stack()

      1. DataFrame 变成 Series, 即 从 `表` 变成 `花括号` 结构

      2. `df_to_ser = ser_to_df.stack()`  

         1. ```
         -11   9   c    0.286925
            -10   10  a    0.866547
            -1    12  c    1.021504
                  14  b    1.188193
             0    20  a   -0.700148
             10   2   b    0.695750
             11   12  c    0.953382
                  25  b   -1.137258
             18  -10  a    0.265473
             21   11  a    1.245911
                  20  c    0.245710
             26   0   b   -0.618138
            ```

         2. 返回 pandas.core.series.Series 类型

7. 主键, 外键

   1. 主键:
      1. 关系型数据库中的一条记录中有若干个属性，若其中某一个属性组(注意是组)能唯一标识一条记录，该属性/属性组可以成为一个主键 
      2. 如  :
         1. 学生表(学号，姓名，性别，班级) 
            其中每个学生的学号是唯一的，`学号` 就是一个主键 
         2. 课程表(课程编号,课程名,学分) 
            其中课程编号是唯一的,`课程编号` 就是一个主键 
         3. 成绩表(学号,课程编号,成绩) 
            成绩表中单一一个属性无法唯一标识一条记录，学号,课程号的组合才可以唯一标识一条记录，所以 学号和课程号的 `属性组` 是一个主键 
   2. 外键
      1. 成绩表中的 `学号` 不是成绩表的主键，但它和学生表中的 `学号` 相对应，并且学生表中的学号是学生表的主键，则称成绩表中的 学号 是学生表的外键 
      2. 同理 成绩表中的课程编号是课程表的外键 
      3. 外键只能引用外表中的值

















